# ç³»ç»Ÿè¯Šæ–­å·¥å…·è®¾è®¡æ–‡æ¡£

## æ¦‚è¿°

æœ¬é¡¹ç›®æ—¨åœ¨å¼€å‘ä¸€ä¸ªæ™ºèƒ½ç³»ç»Ÿè¯Šæ–­å·¥å…·ï¼Œé€šè¿‡æ”¶é›†ç³»ç»Ÿç¡¬ä»¶èµ„æºã€è¿è¡ŒçŠ¶æ€å’Œç½‘ç»œçŠ¶æ€ç­‰ä¿¡æ¯ï¼Œä½¿ç”¨ç«¯ä¾§è½»é‡çº§AIæ¨¡å‹ï¼ˆQwen3-0.6Bï¼‰å’Œå¤šæ™ºèƒ½ä½“ååŒæŠ€æœ¯è¿›è¡Œæ™ºèƒ½è¯Šæ–­å’Œé—®é¢˜åˆ†æã€‚å·¥å…·æä¾›å‹å¥½çš„GUIç•Œé¢ï¼Œæ”¯æŒè·¨å¹³å°è¿è¡Œï¼Œè®©éæŠ€æœ¯äººå‘˜ä¹Ÿèƒ½è½»æ¾ä½¿ç”¨ã€‚

### æ ¸å¿ƒç‰¹æ€§
- å¤šç»´åº¦ç³»ç»Ÿä¿¡æ¯æ”¶é›†ï¼ˆç¡¬ä»¶ã€ç³»ç»ŸçŠ¶æ€ã€ç½‘ç»œï¼‰
- åŸºäºQwen3-0.6Bçš„ç«¯ä¾§AIè¯Šæ–­
- LangGraphå¤šæ™ºèƒ½ä½“ååŒåˆ†æ
- è·¨å¹³å°æ”¯æŒï¼ˆWindowsã€macOSã€Linuxï¼‰
- ç”¨æˆ·å‹å¥½çš„GUIç•Œé¢
- è‡ªåŠ¨æ¨¡å‹ä¸‹è½½å’Œç®¡ç†
- å·¥å…·è°ƒç”¨èƒ½åŠ›æ‰©å±•

## æŠ€æœ¯æ ˆ

### é¡¹ç›®ç®¡ç†
- **åŒ…ç®¡ç†å™¨**: uv (å¿«é€ŸPythonåŒ…ç®¡ç†å™¨)
- **ç‰ˆæœ¬æ§åˆ¶**: Git
- **ä¾èµ–ç®¡ç†**: pyproject.toml + uv.lock
- **è™šæ‹Ÿç¯å¢ƒ**: uvç®¡ç†çš„Pythonè™šæ‹Ÿç¯å¢ƒ

### æ ¸å¿ƒæŠ€æœ¯
- **ç¼–ç¨‹è¯­è¨€**: Python 3.9+
- **AIæ¡†æ¶**: LangChain + LangGraph
- **æ¨¡å‹**: Qwen/Qwen3-0.6B (é€šè¿‡transformersåº“)
- **GUIæ¡†æ¶**: PyQt6 (ç°ä»£åŒ–è·¨å¹³å°GUIæ¡†æ¶)
- **ç³»ç»Ÿä¿¡æ¯æ”¶é›†**: psutil, platform, subprocess
- **ç½‘ç»œç›‘æ§**: requests, ping3, netifaces
- **æ¨¡å‹ç®¡ç†**: huggingface_hub

### è¾…åŠ©åº“
- **é…ç½®ç®¡ç†**: pydantic, yaml
- **æ—¥å¿—**: loguru
- **å¤šçº¿ç¨‹**: threading, asyncio
- **æ‰“åŒ…**: PyInstaller
- **å›¾è¡¨**: matplotlib, plotly, pyqtgraph
- **ç³»ç»Ÿé›†æˆ**: QSystemTrayIcon, QNotification
- **ä¸»é¢˜æ”¯æŒ**: qdarkstyle, qt-material

## æ¶æ„è®¾è®¡

### æ•´ä½“æ¶æ„

```mermaid
graph TB
    subgraph "ç”¨æˆ·ç•Œé¢å±‚"
        GUI[GUIç•Œé¢]
        CLI[å‘½ä»¤è¡Œæ¥å£]
    end
    
    subgraph "åº”ç”¨æœåŠ¡å±‚"
        DM[è¯Šæ–­ç®¡ç†å™¨]
        AM[æ™ºèƒ½ä½“ç®¡ç†å™¨]
        MM[æ¨¡å‹ç®¡ç†å™¨]
    end
    
    subgraph "æ™ºèƒ½ä½“å±‚"
        SA[ç³»ç»Ÿåˆ†ææ™ºèƒ½ä½“]
        NA[ç½‘ç»œåˆ†ææ™ºèƒ½ä½“]
        HA[ç¡¬ä»¶åˆ†ææ™ºèƒ½ä½“]
        CA[åè°ƒæ™ºèƒ½ä½“]
    end
    
    subgraph "æ•°æ®æ”¶é›†å±‚"
        SIC[ç³»ç»Ÿä¿¡æ¯æ”¶é›†å™¨]
        NIC[ç½‘ç»œä¿¡æ¯æ”¶é›†å™¨]
        HIC[ç¡¬ä»¶ä¿¡æ¯æ”¶é›†å™¨]
    end
    
    subgraph "AIå¼•æ“å±‚"
        LLM[Qwen3-0.6Bæ¨¡å‹]
        LG[LangGraphå¼•æ“]
        TC[å·¥å…·è°ƒç”¨å™¨]
    end
    
    subgraph "å·¥å…·å±‚"
        ST[ç³»ç»Ÿå·¥å…·]
        NT[ç½‘ç»œå·¥å…·]
        FT[æ–‡ä»¶å·¥å…·]
    end
    
    GUI --> DM
    CLI --> DM
    DM --> AM
    DM --> MM
    AM --> SA
    AM --> NA
    AM --> HA
    AM --> CA
    SA --> SIC
    NA --> NIC
    HA --> HIC
    SA --> LG
    NA --> LG
    HA --> LG
    CA --> LG
    LG --> LLM
    LG --> TC
    TC --> ST
    TC --> NT
    TC --> FT
```

### å¤šæ™ºèƒ½ä½“ååŒæ¶æ„ - ä¸¥è°¨æ€§è®¾è®¡

#### AIæ¨ç†ä¸¥è°¨æ€§ä¿éšœ
```mermaid
graph LR
    subgraph "æ¨ç†éªŒè¯æµç¨‹"
        INPUT[è¾“å…¥æ•°æ®]
        VALIDATE[æ•°æ®éªŒè¯]
        REASONING[å¤šæ™ºèƒ½ä½“æ¨ç†]
        CONSENSUS[å…±è¯†æœºåˆ¶]
        CONFIDENCE[ç½®ä¿¡åº¦è¯„ä¼°]
        OUTPUT[è¾“å‡ºç»“æœ]
    end
    
    subgraph "è´¨é‡æ§åˆ¶"
        CROSS_CHECK[äº¤å‰éªŒè¯]
        RULE_ENGINE[è§„åˆ™å¼•æ“]
        FALLBACK[é™çº§ç­–ç•¥]
        AUDIT[å®¡è®¡æ—¥å¿—]
    end
    
    INPUT --> VALIDATE
    VALIDATE --> REASONING
    REASONING --> CROSS_CHECK
    CROSS_CHECK --> CONSENSUS
    CONSENSUS --> CONFIDENCE
    CONFIDENCE --> RULE_ENGINE
    RULE_ENGINE --> OUTPUT
    
    VALIDATE -.-> FALLBACK
    REASONING -.-> AUDIT
    CONSENSUS -.-> AUDIT
```

#### ä¸¥è°¨æ€§è®¾è®¡åŸåˆ™
1. **å¤šæ™ºèƒ½ä½“å…±è¯†æœºåˆ¶**: è‡³å°‘3ä¸ªæ™ºèƒ½ä½“å‚ä¸å†³ç­–ï¼Œé‡‡ç”¨æŠ•ç¥¨æœºåˆ¶
2. **ç½®ä¿¡åº¦é‡åŒ–**: æ¯ä¸ªè¯Šæ–­ç»“æœéƒ½æœ‰æ˜ç¡®çš„ç½®ä¿¡åº¦åˆ†æ•°
3. **è§„åˆ™å¼•æ“å…œåº•**: AIæ— æ³•ç¡®å®šæ—¶ä½¿ç”¨ä¸“å®¶è§„åˆ™
4. **å®¡è®¡è¿½è¸ª**: å®Œæ•´è®°å½•æ¨ç†è¿‡ç¨‹å’Œå†³ç­–ä¾æ®
5. **é™çº§ç­–ç•¥**: AIå¤±æ•ˆæ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°ä¼ ç»Ÿè¯Šæ–­æ–¹æ³•

#### æ€è€ƒæ¨ç†æ¨¡å‹è¾“å‡ºæ”¯æŒ

```python
class ChainOfThoughtOutput(BaseModel):
    """æ€è€ƒé“¾è¾“å‡ºç»“æ„"""
    thought_steps: List[str] = Field(description="æ€è€ƒæ­¥éª¤")
    reasoning_chain: List[Dict[str, Any]] = Field(description="æ¨ç†é“¾")
    intermediate_conclusions: List[str] = Field(description="ä¸­é—´ç»“è®º")
    confidence_evolution: List[float] = Field(description="ç½®ä¿¡åº¦å˜åŒ–")
    evidence_used: List[str] = Field(description="ä½¿ç”¨çš„è¯æ®")
    assumptions_made: List[str] = Field(description="åšå‡ºçš„å‡è®¾")
    alternative_hypotheses: List[str] = Field(description="æ›¿ä»£å‡è®¾")
    
class ReasoningAgent(ReactiveAgent):
    """æ”¯æŒæ€è€ƒæ¨ç†çš„æ™ºèƒ½ä½“"""
    
    def __init__(self, name: str, llm, tools: List[Tool], system_prompt: str):
        super().__init__(name, llm, tools, system_prompt)
        self.thought_parser = ThoughtChainParser()
        self.reasoning_validator = ReasoningValidator()
        
    async def execute_with_reasoning(self, input_data: str) -> AsyncGenerator[Dict[str, Any], None]:
        """æ‰§è¡Œå¸¦æœ‰æ€è€ƒæ¨ç†çš„ä»»åŠ¡"""
        try:
            # 1. åˆå§‹åŒ–æ€è€ƒé“¾
            thought_chain = ThoughtChain()
            
            # 2. åˆ†æ®µæ¨ç†æ‰§è¡Œ
            reasoning_stages = [
                "é—®é¢˜ç†è§£",
                "ä¿¡æ¯æ”¶é›†", 
                "å‡è®¾ç”Ÿæˆ",
                "è¯æ®åˆ†æ",
                "ç»“è®ºæ¨å¯¼",
                "ç»“æœéªŒè¯"
            ]
            
            for stage in reasoning_stages:
                yield {
                    "type": "reasoning_stage",
                    "stage": stage,
                    "agent_name": self.name,
                    "timestamp": datetime.now().isoformat()
                }
                
                # æ‰§è¡Œå½“å‰é˜¶æ®µçš„æ¨ç†
                stage_result = await self._execute_reasoning_stage(stage, input_data, thought_chain)
                
                yield {
                    "type": "reasoning_result",
                    "stage": stage,
                    "result": stage_result,
                    "thought_chain": thought_chain.get_current_state(),
                    "confidence": stage_result.get("confidence", 0.0)
                }
                
                # éªŒè¯æ¨ç†è´¨é‡
                validation_result = self.reasoning_validator.validate_stage(stage_result)
                if not validation_result.is_valid:
                    yield {
                        "type": "reasoning_error",
                        "stage": stage,
                        "error": validation_result.error_message,
                        "suggested_action": validation_result.suggested_action
                    }
                    break
                    
            # 3. ç”Ÿæˆæœ€ç»ˆç»“æœ
            final_result = self._generate_final_reasoning_result(thought_chain)
            
            yield {
                "type": "reasoning_complete",
                "result": final_result.dict(),
                "thought_chain_summary": thought_chain.get_summary(),
                "total_confidence": final_result.confidence_score
            }
            
        except Exception as e:
            yield {
                "type": "reasoning_error",
                "error": str(e),
                "stage": "execution"
            }
            
    async def _execute_reasoning_stage(self, stage: str, input_data: str, 
                                     thought_chain: 'ThoughtChain') -> Dict[str, Any]:
        """æ‰§è¡Œå…·ä½“çš„æ¨ç†é˜¶æ®µ"""
        
        stage_prompts = {
            "é—®é¢˜ç†è§£": f"""
è¯·ä»”ç»†ç†è§£ä»¥ä¸‹ç³»ç»Ÿè¯Šæ–­é—®é¢˜:
{input_data}

è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ€è€ƒ:
1. è¯†åˆ«æ ¸å¿ƒé—®é¢˜
2. ç¡®å®šå…³é”®ä¿¡æ¯
3. åˆ—å‡ºå¯èƒ½çš„åŸå› 
4. è¯„ä¼°é—®é¢˜çš„ä¼˜å…ˆçº§

è¯·æä¾›ä½ çš„æ€è€ƒè¿‡ç¨‹å’Œåˆæ­¥ç»“è®ºã€‚
            """,
            
            "ä¿¡æ¯æ”¶é›†": f"""
åŸºäºä¹‹å‰çš„é—®é¢˜ç†è§£ï¼Œç°åœ¨éœ€è¦æ”¶é›†ç›¸å…³ä¿¡æ¯:
{input_data}

å½“å‰æ€è€ƒé“¾: {thought_chain.get_summary()}

è¯·æ€è€ƒ:
1. éœ€è¦å“ªäº›å…·ä½“æ•°æ®
2. å¦‚ä½•è·å–è¿™äº›æ•°æ®
3. æ•°æ®çš„å¯é æ€§å¦‚ä½•
4. è¿˜ç¼ºå°‘å“ªäº›ä¿¡æ¯

è¯·ä½¿ç”¨å¯ç”¨çš„å·¥å…·æ”¶é›†ä¿¡æ¯å¹¶æä¾›ä½ çš„åˆ†æã€‚
            """
        }
        
        prompt = stage_prompts.get(stage, f"æ‰§è¡Œ{stage}é˜¶æ®µçš„æ¨ç†")
        
        # è°ƒç”¨LLMè¿›è¡Œæ¨ç†
        response = await self.llm.ainvoke(prompt)
        
        # è§£ææ€è€ƒè¿‡ç¨‹
        thought_result = self.thought_parser.parse_response(response.content)
        
        # æ›´æ–°æ€è€ƒé“¾
        thought_chain.add_stage(stage, thought_result)
        
        return {
            "stage": stage,
            "thoughts": thought_result.thought_steps,
            "reasoning": thought_result.reasoning_chain,
            "confidence": thought_result.confidence_score,
            "evidence": thought_result.evidence_used,
            "timestamp": datetime.now().isoformat()
        }
        
class ThoughtChain:
    """æ€è€ƒé“¾ç®¡ç†å™¨"""
    
    def __init__(self):
        self.stages = []
        self.overall_confidence = 0.0
        self.key_insights = []
        
    def add_stage(self, stage_name: str, thought_result: ChainOfThoughtOutput):
        """æ·»åŠ æ¨ç†é˜¶æ®µ"""
        self.stages.append({
            "stage": stage_name,
            "result": thought_result,
            "timestamp": datetime.now().isoformat()
        })
        
        # æ›´æ–°æ•´ä½“ç½®ä¿¡åº¦
        self._update_overall_confidence()
        
    def get_current_state(self) -> Dict[str, Any]:
        """è·å–å½“å‰æ€è€ƒé“¾çŠ¶æ€"""
        return {
            "stages_completed": len(self.stages),
            "current_confidence": self.overall_confidence,
            "key_insights": self.key_insights,
            "latest_thoughts": self.stages[-1]["result"].thought_steps if self.stages else []
        }
        
    def get_summary(self) -> str:
        """è·å–æ€è€ƒé“¾æ‘˜è¦"""
        if not self.stages:
            return "æš‚æ— æ€è€ƒè®°å½•"
            
        summary_parts = []
        for stage in self.stages:
            stage_summary = f"{stage['stage']}: {stage['result'].intermediate_conclusions[0] if stage['result'].intermediate_conclusions else 'æ— ç»“è®º'}"
            summary_parts.append(stage_summary)
            
        return " -> ".join(summary_parts)
        
    def _update_overall_confidence(self):
        """æ›´æ–°æ•´ä½“ç½®ä¿¡åº¦"""
        if self.stages:
            confidences = [stage["result"].confidence_score for stage in self.stages]
            self.overall_confidence = sum(confidences) / len(confidences)
            
class ThoughtChainParser:
    """æ€è€ƒé“¾è§£æå™¨"""
    
    def parse_response(self, response_text: str) -> ChainOfThoughtOutput:
        """è§£æLLMå“åº”ä¸­çš„æ€è€ƒè¿‡ç¨‹"""
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ€è€ƒæ­¥éª¤
        import re
        
        thought_pattern = r'æ€è€ƒ[\s]*[:ï¼š]([\s\S]*?)(?=\n\n|ç»“è®º|å‡è®¾|$)'
        reasoning_pattern = r'æ¨ç†[\s]*[:ï¼š]([\s\S]*?)(?=\n\n|ç»“è®º|$)'
        conclusion_pattern = r'ç»“è®º[\s]*[:ï¼š]([\s\S]*?)(?=\n\n|$)'
        
        thought_steps = re.findall(thought_pattern, response_text)
        reasoning_chains = re.findall(reasoning_pattern, response_text) 
        conclusions = re.findall(conclusion_pattern, response_text)
        
        return ChainOfThoughtOutput(
            thought_steps=[step.strip() for step in thought_steps],
            reasoning_chain=self._parse_reasoning_chain(reasoning_chains),
            intermediate_conclusions=[conc.strip() for conc in conclusions],
            confidence_evolution=[0.5],  # é»˜è®¤å€¼
            evidence_used=[],
            assumptions_made=[],
            alternative_hypotheses=[],
            confidence_score=0.5
        )
        
    def _parse_reasoning_chain(self, reasoning_texts: List[str]) -> List[Dict[str, Any]]:
        """è§£ææ¨ç†é“¾"""
        reasoning_chain = []
        for i, text in enumerate(reasoning_texts):
            reasoning_chain.append({
                "step": i + 1,
                "content": text.strip(),
                "type": "deduction"
            })
        return reasoning_chain
        
class ReasoningValidator:
    """æ¨ç†éªŒè¯å™¨"""
    
    def validate_stage(self, stage_result: Dict[str, Any]) -> 'ValidationResult':
        """éªŒè¯æ¨ç†é˜¶æ®µçš„è´¨é‡"""
        confidence = stage_result.get("confidence", 0.0)
        thoughts = stage_result.get("thoughts", [])
        reasoning = stage_result.get("reasoning", [])
        
        # æ£€æŸ¥éªŒè¯æ¡ä»¶
        if confidence < 0.3:
            return ValidationResult(
                is_valid=False,
                error_message="æ¨ç†ç½®ä¿¡åº¦è¿‡ä½",
                suggested_action="éœ€è¦æ›´å¤šè¯æ®æˆ–é‡æ–°åˆ†æ"
            )
            
        if len(thoughts) < 2:
            return ValidationResult(
                is_valid=False,
                error_message="æ€è€ƒæ­¥éª¤ä¸å¤Ÿè¯¦ç»†",
                suggested_action="éœ€è¦æ›´å¤šçš„æ€è€ƒæ­¥éª¤"
            )
            
        return ValidationResult(
            is_valid=True,
            error_message="",
            suggested_action=""
        )
```

class AIReasoningEngine:
    """å¢å¼ºçš„AIæ¨ç†å¼•æ“ï¼Œæ”¯æŒæ€è€ƒé“¾å’Œä¸¥è°¨æ€§éªŒè¯"""
    
    def __init__(self):
        self.agents = {
            'hardware': HardwareAnalysisAgent(),
            'system': SystemAnalysisAgent(), 
            'network': NetworkAnalysisAgent(),
            'validator': ValidationAgent()
        }
        self.rule_engine = ExpertRuleEngine()
        self.confidence_threshold = 0.7
        self.audit_logger = AuditLogger()
        self.reasoning_aggregator = ReasoningAggregator()
        
    async def diagnose_with_reasoning_consensus(self, data: SystemData) -> AsyncGenerator[Dict[str, Any], None]:
        """å¸¦æœ‰æ€è€ƒæ¨ç†çš„å…±è¯†è¯Šæ–­"""
        try:
            # 1. åˆå§‹åŒ–é˜¶æ®µ
            yield {
                "type": "diagnosis_start",
                "message": "å¯åŠ¨å¤šæ™ºèƒ½ä½“ååŒè¯Šæ–­",
                "reasoning_mode": "chain_of_thought",
                "agents_count": len(self.agents)
            }
            
            # 2. æ•°æ®éªŒè¯
            if not self._validate_input_data(data):
                yield {
                    "type": "validation_failed",
                    "message": "è¾“å…¥æ•°æ®éªŒè¯å¤±è´¥ï¼Œåˆ‡æ¢åˆ°é™çº§ç­–ç•¥",
                    "fallback_strategy": "rule_based_diagnosis"
                }
                
                fallback_result = await self._fallback_diagnosis(data)
                yield fallback_result
                return
                
            # 3. å¤šæ™ºèƒ½ä½“å¹¶è¡Œæ¨ç†
            agent_reasoning_results = {}
            
            for agent_name, agent in self.agents.items():
                yield {
                    "type": "agent_reasoning_start",
                    "agent_name": agent_name,
                    "message": f"å¯åŠ¨{agent_name}æ™ºèƒ½ä½“æ€è€ƒæ¨ç†"
                }
                
                # æµå¼æ‰§è¡Œæ™ºèƒ½ä½“æ¨ç†
                agent_result = None
                async for reasoning_update in agent.execute_with_reasoning(self._format_data_for_agent(agent_name, data)):
                    yield {
                        "type": "agent_reasoning_update",
                        "agent_name": agent_name,
                        "update": reasoning_update
                    }
                    
                    if reasoning_update["type"] == "reasoning_complete":
                        agent_result = reasoning_update["result"]
                        
                agent_reasoning_results[agent_name] = agent_result
                
            # 4. äº¤å‰éªŒè¯æ¨ç†è¿‡ç¨‹
            yield {
                "type": "cross_validation_start",
                "message": "å¼€å§‹äº¤å‰éªŒè¯æ™ºèƒ½ä½“æ¨ç†ç»“æœ"
            }
            
            validated_results = self._cross_validate_reasoning(agent_reasoning_results)
            
            yield {
                "type": "cross_validation_complete",
                "validation_summary": self._get_validation_summary(validated_results)
            }
            
            # 5. å…±è¯†æ„å»ºä¸æ¨ç†èšåˆ
            yield {
                "type": "consensus_reasoning_start",
                "message": "æ„å»ºæ™ºèƒ½ä½“å…±è¯†å’Œèšåˆæ¨ç†ç»“æœ"
            }
            
            consensus_result = await self.reasoning_aggregator.aggregate_reasoning_results(
                validated_results
            )
            
            async for consensus_update in consensus_result:
                yield {
                    "type": "consensus_update", 
                    "update": consensus_update
                }
                
            # 6. æœ€ç»ˆç½®ä¿¡åº¦è¯„ä¼°
            final_confidence = self._calculate_consensus_confidence(consensus_result)
            
            yield {
                "type": "confidence_assessment",
                "confidence_score": final_confidence,
                "confidence_breakdown": self._get_confidence_breakdown(validated_results)
            }
            
            # 7. è§„åˆ™å¼•æ“éªŒè¯ï¼ˆå¦‚éœ€ï¼‰
            if final_confidence < self.confidence_threshold:
                yield {
                    "type": "rule_engine_validation",
                    "message": f"ç½®ä¿¡åº¦ä½äºé˜ˆå€¼({self.confidence_threshold})ï¼Œå¯ç”¨è§„åˆ™å¼•æ“éªŒè¯"
                }
                
                rule_results = self.rule_engine.evaluate_all_rules(data.dict())
                consensus_result = self._merge_ai_rule_results(consensus_result, rule_results)
                
            # 8. ç”Ÿæˆæœ€ç»ˆè¯Šæ–­ç»“æœ
            final_result = DiagnosisResult(
                issues=consensus_result.get("issues", []),
                recommendations=consensus_result.get("recommendations", []),
                confidence=final_confidence,
                reasoning_summary=consensus_result.get("reasoning_summary", ""),
                thought_chains=self._extract_thought_chains(agent_reasoning_results),
                validation_status="VALIDATED" if final_confidence >= self.confidence_threshold else "PARTIAL",
                rule_engine_used=final_confidence < self.confidence_threshold
            )
            
            yield {
                "type": "diagnosis_complete",
                "result": final_result.dict(),
                "total_confidence": final_confidence,
                "reasoning_quality": self._assess_reasoning_quality(agent_reasoning_results)
            }
            
        except Exception as e:
            yield {
                "type": "diagnosis_error",
                "error": str(e),
                "fallback_available": True
            }
            
            # ç´§æ€¥é™çº§å¤„ç†
            fallback_result = await self._emergency_fallback_diagnosis(data)
            yield fallback_result
            
    def _cross_validate_reasoning(self, agent_results: Dict[str, Any]) -> Dict[str, Any]:
        """äº¤å‰éªŒè¯æ™ºèƒ½ä½“æ¨ç†è¿‡ç¨‹"""
        validated_results = {}
        
        for agent_name, result in agent_results.items():
            if not result:
                continue
                
            validation_scores = []
            reasoning_consistency = []
            
            # ä¸å…¶ä»–æ™ºèƒ½ä½“çš„æ¨ç†è¿‡ç¨‹å¯¹æ¯”
            for other_agent, other_result in agent_results.items():
                if other_agent != agent_name and other_result:
                    # æ¯”è¾ƒæ¨ç†é“¾çš„ä¸€è‡´æ€§
                    consistency_score = self._compare_reasoning_chains(
                        result.get("thought_chain_summary", ""),
                        other_result.get("thought_chain_summary", "")
                    )
                    reasoning_consistency.append(consistency_score)
                    
                    # æ¯”è¼ƒç»“è®ºçš„ç›¸ä¼¼æ€§
                    conclusion_similarity = self._compare_conclusions(
                        result.get("result", {}),
                        other_result.get("result", {})
                    )
                    validation_scores.append(conclusion_similarity)
                    
            validated_results[agent_name] = {
                "original_result": result,
                "reasoning_consistency": sum(reasoning_consistency) / len(reasoning_consistency) if reasoning_consistency else 0.0,
                "conclusion_similarity": sum(validation_scores) / len(validation_scores) if validation_scores else 0.0,
                "validation_confidence": (sum(reasoning_consistency + validation_scores) / len(reasoning_consistency + validation_scores)) if (reasoning_consistency + validation_scores) else 0.0
            }
            
        return validated_results
        
    def _extract_thought_chains(self, agent_results: Dict[str, Any]) -> Dict[str, List[str]]:
        """æå–æ‰€æœ‰æ™ºèƒ½ä½“çš„æ€è€ƒé“¾"""
        thought_chains = {}
        
        for agent_name, result in agent_results.items():
            if result and "thought_chain_summary" in result:
                thought_chains[agent_name] = result["thought_chain_summary"]
                
        return thought_chains
        
    def _assess_reasoning_quality(self, agent_results: Dict[str, Any]) -> Dict[str, float]:
        """è¯„ä¼°æ¨ç†è´¨é‡"""
        quality_metrics = {
            "avg_confidence": 0.0,
            "reasoning_depth": 0.0,
            "evidence_strength": 0.0,
            "logical_consistency": 0.0
        }
        
        if not agent_results:
            return quality_metrics
            
        confidences = []
        reasoning_depths = []
        
        for agent_name, result in agent_results.items():
            if result:
                confidences.append(result.get("total_confidence", 0.0))
                
                # è¯„ä¼°æ¨ç†æ·±åº¦ï¼ˆåŸºäºæ€è€ƒæ­¥éª¤æ•°é‡ï¼‰
                thought_steps = result.get("thought_chain_summary", "")
                reasoning_depth = len(thought_steps.split(" -> ")) if thought_steps else 0
                reasoning_depths.append(reasoning_depth)
                
        quality_metrics["avg_confidence"] = sum(confidences) / len(confidences) if confidences else 0.0
        quality_metrics["reasoning_depth"] = sum(reasoning_depths) / len(reasoning_depths) if reasoning_depths else 0.0
        
        return quality_metrics
        
class ReasoningAggregator:
    """æ¨ç†ç»“æœèšåˆå™¨"""
    
    async def aggregate_reasoning_results(self, validated_results: Dict[str, Any]) -> AsyncGenerator[Dict[str, Any], None]:
        """èšåˆå¤šä¸ªæ™ºèƒ½ä½“çš„æ¨ç†ç»“æœ"""
        
        yield {
            "type": "aggregation_start",
            "participating_agents": list(validated_results.keys())
        }
        
        # 1. æŒ‰ç½®ä¿¡åº¦åŠ æƒèšåˆ
        weighted_issues = []
        weighted_recommendations = []
        combined_reasoning = []
        
        for agent_name, validation_data in validated_results.items():
            weight = validation_data["validation_confidence"]
            result = validation_data["original_result"]
            
            if "result" in result:
                agent_issues = result["result"].get("issues", [])
                agent_recommendations = result["result"].get("recommendations", [])
                
                # åŠ æƒèšåˆé—®é¢˜
                for issue in agent_issues:
                    weighted_issues.append({
                        "issue": issue,
                        "weight": weight,
                        "source_agent": agent_name
                    })
                    
                # åŠ æƒèšåˆå»ºè®®
                for rec in agent_recommendations:
                    weighted_recommendations.append({
                        "recommendation": rec,
                        "weight": weight,
                        "source_agent": agent_name
                    })
                    
                # æ”¶é›†æ¨ç†è¿‡ç¨‹
                if "thought_chain_summary" in result:
                    combined_reasoning.append({
                        "agent": agent_name,
                        "reasoning": result["thought_chain_summary"],
                        "confidence": result.get("total_confidence", 0.0)
                    })
                    
        yield {
            "type": "aggregation_progress",
            "stage": "weighting_complete",
            "weighted_issues_count": len(weighted_issues),
            "weighted_recommendations_count": len(weighted_recommendations)
        }
        
        # 2. æŒ‰ç±»åˆ«å’Œæƒé‡æ’åº
        final_issues = self._rank_weighted_items(weighted_issues, "issue")
        final_recommendations = self._rank_weighted_items(weighted_recommendations, "recommendation")
        
        # 3. ç”Ÿæˆç»¼åˆæ¨ç†æ‘˜è¦
        reasoning_summary = self._generate_reasoning_summary(combined_reasoning)
        
        yield {
            "type": "aggregation_complete",
            "final_issues": final_issues,
            "final_recommendations": final_recommendations,
            "reasoning_summary": reasoning_summary,
            "aggregation_confidence": self._calculate_aggregation_confidence(validated_results)
        }
        
    def _rank_weighted_items(self, weighted_items: List[Dict], item_key: str) -> List[Dict]:
        """æŒ‰æƒé‡æ’åºé¡¹ç›®"""
        # æŒ‰æƒé‡é™åºæ’åº
        sorted_items = sorted(weighted_items, key=lambda x: x["weight"], reverse=True)
        
        # å»é‡å¹¶åˆå¹¶ç›¸ä¼¼çš„é¡¹ç›®
        unique_items = []
        seen_items = set()
        
        for item in sorted_items:
            item_content = str(item[item_key])
            if item_content not in seen_items:
                unique_items.append(item)
                seen_items.add(item_content)
                
        return unique_items[:10]  # è¿”å›å‰10ä¸ªæœ€é‡è¦çš„é¡¹ç›®
        
    def _generate_reasoning_summary(self, combined_reasoning: List[Dict]) -> str:
        """ç”Ÿæˆç»¼åˆæ¨ç†æ‘˜è¦"""
        if not combined_reasoning:
            return "æ— å¯ç”¨çš„æ¨ç†ä¿¡æ¯"
            
        # æŒ‰ç½®ä¿¡åº¦æ’åº
        sorted_reasoning = sorted(combined_reasoning, key=lambda x: x["confidence"], reverse=True)
        
        summary_parts = []
        for reasoning in sorted_reasoning:
            agent_summary = f"{reasoning['agent']}: {reasoning['reasoning']} (ç½®ä¿¡åº¦: {reasoning['confidence']:.2f})"
            summary_parts.append(agent_summary)
            
        return "; ".join(summary_parts)
```

```python
from langchain.agents import create_react_agent
from langchain.tools import Tool
from langchain_core.prompts import PromptTemplate
from langchain.schema.output_parser import OutputParserException
from pydantic import BaseModel, Field
from typing import AsyncGenerator, Dict, Any, List
import json
import asyncio

class StructuredDiagnosisOutput(BaseModel):
    """ç»“æ„åŒ–è¯Šæ–­è¾“å‡º"""
    issue_category: str = Field(description="é—®é¢˜ç±»åˆ«")
    severity_level: str = Field(description="ä¸¥é‡ç¨‹åº¦ (critical/high/medium/low)")
    confidence_score: float = Field(description="ç½®ä¿¡åº¦åˆ†æ•° 0.0-1.0")
    root_cause: str = Field(description="æ ¹å› åˆ†æ")
    impact_description: str = Field(description="å½±å“æè¿°")
    recommended_actions: List[str] = Field(description="å»ºè®®æ“ä½œ")
    affected_components: List[str] = Field(description="å—å½±å“ç»„ä»¶")
    reasoning_steps: List[str] = Field(description="æ¨ç†æ­¥éª¤")
    validation_evidence: Dict[str, Any] = Field(description="éªŒè¯è¯æ®")

class StreamingAgentStatus(BaseModel):
    """æµå¼è¾“å‡ºçš„æ™ºèƒ½ä½“çŠ¶æ€"""
    agent_name: str
    current_stage: str
    progress_percentage: float
    current_action: str
    tool_calls: List[Dict[str, Any]]
    intermediate_results: Dict[str, Any]
    timestamp: str

class ReactiveAgent:
    """åŸºäºcreate_react_agentçš„æ™ºèƒ½ä½“åŸºç±»"""
    
    def __init__(self, name: str, llm, tools: List[Tool], system_prompt: str):
        self.name = name
        self.llm = llm
        self.tools = tools
        self.system_prompt = system_prompt
        self.current_stage = "idle"
        self.progress = 0.0
        self.status_callbacks = []
        
        # åˆ›å»º React Agent
        self.agent = self._create_react_agent()
        
    def _create_react_agent(self):
        """åˆ›å»º React Agent"""
        prompt_template = PromptTemplate.from_template(
            """
{system_prompt}

ä½ æœ‰ä»¥ä¸‹å·¥å…·å¯ä»¥ä½¿ç”¨:
{tools}

ä½¿ç”¨ä»¥ä¸‹æ ¼å¼:

Question: ä½ éœ€è¦å›ç­”çš„é—®é¢˜
Thought: ä½ åº”è¯¥æ€»æ˜¯æ€è€ƒä½ è¦åšä»€ä¹ˆ
Action: è¦é‡‡å–çš„è¡ŒåŠ¨ï¼Œåº”è¯¥æ˜¯[{tool_names}]ä¹‹ä¸€
Action Input: è¡ŒåŠ¨çš„è¾“å…¥
Observation: è¡ŒåŠ¨çš„ç»“æœ
... (è¿™ä¸ªThought/Action/Action Input/Observationå¯ä»¥é‡å¤Næ¬¡)
Thought: æˆ‘ç°åœ¨çŸ¥é“æœ€ç»ˆç­”æ¡ˆäº†
Final Answer: æœ€ç»ˆç­”æ¡ˆï¼Œå¿…é¡»æ˜¯ç»“æ„åŒ–çš„JSONæ ¼å¼

å¼€å§‹!

Question: {input}
{agent_scratchpad}
            """
        )
        
        return create_react_agent(
            llm=self.llm,
            tools=self.tools,
            prompt=prompt_template
        )
        
    def add_status_callback(self, callback):
        """æ·»åŠ çŠ¶æ€å›è°ƒ"""
        self.status_callbacks.append(callback)
        
    def _notify_status_change(self, stage: str, progress: float, action: str = "", 
                            tool_calls: List = None, results: Dict = None):
        """é€šçŸ¥çŠ¶æ€å˜æ›´"""
        self.current_stage = stage
        self.progress = progress
        
        status = StreamingAgentStatus(
            agent_name=self.name,
            current_stage=stage,
            progress_percentage=progress,
            current_action=action,
            tool_calls=tool_calls or [],
            intermediate_results=results or {},
            timestamp=datetime.now().isoformat()
        )
        
        for callback in self.status_callbacks:
            try:
                callback(status)
            except Exception as e:
                logger.error(f"çŠ¶æ€å›è°ƒé”™è¯¯: {e}")
                
    async def execute_streaming(self, input_data: str) -> AsyncGenerator[StreamingAgentStatus, None]:
        """æµå¼æ‰§è¡Œæ™ºèƒ½ä½“ä»»åŠ¡"""
        try:
            self._notify_status_change("starting", 0.0, "åˆå§‹åŒ–æ™ºèƒ½ä½“")
            yield self._create_status_update()
            
            # æ¨¡æ‹Ÿåˆ†æ®µæ‰§è¡Œ
            stages = [
                ("analyzing", 20.0, "åˆ†æè¾“å…¥æ•°æ®"),
                ("tool_calling", 50.0, "è°ƒç”¨è¯Šæ–­å·¥å…·"),
                ("reasoning", 80.0, "è¿›è¡Œé€»è¾‘æ¨ç†"),
                ("validating", 95.0, "éªŒè¯ç»“æœ"),
                ("completed", 100.0, "å®Œæˆè¯Šæ–­")
            ]
            
            for stage, progress, action in stages:
                self._notify_status_change(stage, progress, action)
                yield self._create_status_update()
                await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
                
        except Exception as e:
            logger.error(f"æ™ºèƒ½ä½“æ‰§è¡Œé”™è¯¯: {e}")
            self._notify_status_change("error", 0.0, f"æ‰§è¡Œé”™è¯¯: {str(e)}")
            yield self._create_status_update()
            
    def _create_status_update(self) -> StreamingAgentStatus:
        """åˆ›å»ºçŠ¶æ€æ›´æ–°"""
        return StreamingAgentStatus(
            agent_name=self.name,
            current_stage=self.current_stage,
            progress_percentage=self.progress,
            current_action="",
            tool_calls=[],
            intermediate_results={},
            timestamp=datetime.now().isoformat()
        )
        
class HardwareAnalysisAgent(ReactiveAgent):
    """ç¡¬ä»¶åˆ†ææ™ºèƒ½ä½“"""
    
    def __init__(self, llm, hardware_tools: List[Tool]):
        system_prompt = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¡¬ä»¶è¯Šæ–­ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç³»ç»Ÿç¡¬ä»¶çŠ¶æ€ï¼ŒåŒ…æ‹¬:
1. CPUæ€§èƒ½å’Œæ¸©åº¦åˆ†æ
2. å†…å­˜ä½¿ç”¨æƒ…å†µå’Œå¥åº·çŠ¶æ€
3. å­˜å‚¨è®¾å¤‡æ€§èƒ½å’Œç©ºé—´åˆ†æ
4. æ¸©åº¦ä¼ æ„Ÿå™¨å’Œæ•£çƒ­æƒ…å†µ
5. ç”µæºå’Œèƒ½è€—åˆ†æ

ä½ å¿…é¡»æä¾›ç»“æ„åŒ–çš„JSONè¾“å‡ºï¼ŒåŒ…å«ç½®ä¿¡åº¦åˆ†æ•°å’Œè¯¦ç»†çš„æ¨ç†è¿‡ç¨‹ã€‚
        """
        super().__init__("HardwareAnalysisAgent", llm, hardware_tools, system_prompt)
        
class SystemAnalysisAgent(ReactiveAgent):
    """ç³»ç»Ÿåˆ†ææ™ºèƒ½ä½“"""
    
    def __init__(self, llm, system_tools: List[Tool]):
        system_prompt = """
ä½ æ˜¯ä¸€ä¸ªç³»ç»Ÿç®¡ç†ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†ææ“ä½œç³»ç»ŸçŠ¶æ€ï¼ŒåŒ…æ‹¬:
1. è¿›ç¨‹å’ŒæœåŠ¡çŠ¶æ€åˆ†æ
2. ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ
3. ç³»ç»Ÿæ—¥å¿—å’Œé”™è¯¯åˆ†æ
4. ç³»ç»Ÿé…ç½®å’Œå®‰å…¨çŠ¶æ€
5. ç³»ç»Ÿæ€§èƒ½å’Œç¨³å®šæ€§è¯„ä¼°

ä½ å¿…é¡»æä¾›ç»“æ„åŒ–çš„JSONè¾“å‡ºï¼ŒåŒ…å«ç½®ä¿¡åº¦åˆ†æ•°å’Œè¯¦ç»†çš„æ¨ç†è¿‡ç¨‹ã€‚
        """
        super().__init__("SystemAnalysisAgent", llm, system_tools, system_prompt)
        
class NetworkAnalysisAgent(ReactiveAgent):
    """ç½‘ç»œåˆ†ææ™ºèƒ½ä½“"""
    
    def __init__(self, llm, network_tools: List[Tool]):
        system_prompt = """
ä½ æ˜¯ä¸€ä¸ªç½‘ç»œè¯Šæ–­ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç½‘ç»œçŠ¶æ€ï¼ŒåŒ…æ‹¬:
1. ç½‘ç»œè¿æ¥çŠ¶æ€å’Œè´¨é‡
2. å¸¦å®½ä½¿ç”¨æƒ…å†µå’Œæ€§èƒ½
3. DNSè§£æå’Œç½‘ç»œå»¶è¿Ÿ
4. ç½‘ç»œå®‰å…¨å’Œé˜²ç«å¢™çŠ¶æ€
5. ç½‘ç»œé…ç½®å’Œè·¯ç”±åˆ†æ

ä½ å¿…é¡»æä¾›ç»“æ„åŒ–çš„JSONè¾“å‡ºï¼ŒåŒ…å«ç½®ä¿¡åº¦åˆ†æ•°å’Œè¯¦ç»†çš„æ¨ç†è¿‡ç¨‹ã€‚
        """
        super().__init__("NetworkAnalysisAgent", llm, network_tools, system_prompt)
        
class ValidationAgent(ReactiveAgent):
    """éªŒè¯æ™ºèƒ½ä½“"""
    
    def __init__(self, llm, validation_tools: List[Tool]):
        system_prompt = """
ä½ æ˜¯ä¸€ä¸ªç³»ç»Ÿè¯Šæ–­éªŒè¯ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯éªŒè¯å…¶ä»–æ™ºèƒ½ä½“çš„è¯Šæ–­ç»“æœï¼ŒåŒ…æ‹¬:
1. äº¤å‰éªŒè¯è¯Šæ–­ç»“æœçš„ä¸€è‡´æ€§
2. æ£€æŸ¥è¯Šæ–­é€»è¾‘çš„åˆç†æ€§
3. éªŒè¯è¯æ®çš„å¯é æ€§
4. è¯„ä¼°ç½®ä¿¡åº¦çš„å‡†ç¡®æ€§
5. æå‡ºæ”¹è¿›å»ºè®®

ä½ å¿…é¡»æä¾›ç»“æ„åŒ–çš„JSONè¾“å‡ºï¼ŒåŒ…å«éªŒè¯ç»“æœå’Œç½®ä¿¡åº¦è¯„ä¼°ã€‚
        """
        super().__init__("ValidationAgent", llm, validation_tools, system_prompt)
```

### è§„åˆ™å¼•æ“ç³»ç»Ÿ

```python
class ExpertRuleEngine:
    """ä¸“å®¶è§„åˆ™å¼•æ“ï¼Œæ”¯æŒå†…ç½®é»˜è®¤è§„åˆ™å’ŒGitä»“åº“è§„åˆ™æ›´æ–°"""
    
    def __init__(self):
        self.rules_dir = Path.home() / ".sysgraph" / "rules"
        self.builtin_rules = self._load_builtin_rules()
        self.git_rules = self._load_git_rules()
        self.rule_updater = RuleUpdater()
        
    def _load_builtin_rules(self) -> List[DiagnosticRule]:
        """åŠ è½½å†…ç½®é»˜è®¤è§„åˆ™"""
        return [
            # CPUé˜ˆå€¼è§„åˆ™
            DiagnosticRule(
                id="cpu_usage_high",
                name="CPUä½¿ç”¨ç‡è¿‡é«˜",
                condition={"metric": "cpu_usage", "operator": ">", "value": 85},
                action={"type": "alert", "message": "CPUä½¿ç”¨ç‡è¿‡é«˜"}
            ),
            # å†…å­˜é˜ˆå€¼è§„åˆ™
            DiagnosticRule(
                id="memory_critical",
                name="å†…å­˜ä½¿ç”¨ä¸¥é‡",
                condition={"metric": "memory_usage", "operator": ">", "value": 90},
                action={"type": "critical", "message": "å†…å­˜ä½¿ç”¨ç‡ä¸¥é‡"}
            )
        ]
        
    def update_rules_from_git(self) -> bool:
        """ä» Git ä»“åº“æ›´æ–°è§„åˆ™"""
        return self.rule_updater.update_rules_from_git()
        
    def evaluate_all_rules(self, data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """è¯„ä¼°æ‰€æœ‰è§„åˆ™å¹¶è¿”å›è§¦å‘çš„è§„åˆ™ç»“æœ"""
        results = []
        all_rules = self.builtin_rules + self.git_rules
        
        for rule in all_rules:
            if self._evaluate_rule(rule, data):
                results.append({
                    "rule_id": rule.id,
                    "message": rule.action["message"],
                    "severity": rule.action["type"]
                })
        return results

class RuleUpdater:
    """è§„åˆ™æ›´æ–°å™¨ï¼Œæ”¯æŒä» GitHub/Gitea ä»“åº“æ›´æ–°è§„åˆ™"""
    
    def __init__(self):
        self.git_config = {
            "repository_url": "https://git.example.com/rules/diagnostic-rules.git",
            "branch": "main",
            "auto_update": True
        }
        
    def update_rules_from_git(self) -> bool:
        """ä» Git ä»“åº“æ›´æ–°è§„åˆ™æ–‡ä»¶"""
        try:
            # å…‹éš†æˆ–æ›´æ–°ä»“åº“
            # éªŒè¯è§„åˆ™æ–‡ä»¶æ ¼å¼
            # åŠ è½½æ–°è§„åˆ™
            return True
        except Exception as e:
            logger.error(f"æ›´æ–°è§„åˆ™å¤±è´¥: {e}")
            return False
```

#### æµå¼è¾“å‡ºå’Œæ¸²æŸ“ç³»ç»Ÿ

```python
class StreamingDiagnosisEngine:
    """æµå¼è¯Šæ–­å¼•æ“"""
    
    def __init__(self):
        self.agents = {}
        self.rule_engine = ExpertRuleEngine()
        self.output_renderer = DiagnosisRenderer()
        self.stream_callbacks = []
        
    def add_stream_callback(self, callback):
        """æ·»åŠ æµå¼è¾“å‡ºå›è°ƒ"""
        self.stream_callbacks.append(callback)
        
    async def start_streaming_diagnosis(self, system_data: SystemData) -> AsyncGenerator[Dict[str, Any], None]:
        """å¼€å§‹æµå¼è¯Šæ–­"""
        try:
            # 1. åˆå§‹åŒ–é˜¶æ®µ
            yield {
                "type": "diagnosis_start",
                "timestamp": datetime.now().isoformat(),
                "message": "å¼€å§‹ç³»ç»Ÿè¯Šæ–­",
                "agents_count": len(self.agents)
            }
            
            # 2. æ•°æ®éªŒè¯é˜¶æ®µ
            yield {
                "type": "data_validation",
                "timestamp": datetime.now().isoformat(),
                "message": "éªŒè¯è¾“å…¥æ•°æ®",
                "validation_result": self._validate_system_data(system_data)
            }
            
            # 3. å¤šæ™ºèƒ½ä½“å¹¶è¡Œæ‰§è¡Œ
            agent_tasks = []
            for agent_name, agent in self.agents.items():
                task = self._execute_agent_with_streaming(agent, system_data)
                agent_tasks.append((agent_name, task))
                
            # 4. æµå¼è¾“å‡ºæ™ºèƒ½ä½“ç»“æœ
            agent_results = {}
            async for agent_name, task in agent_tasks:
                async for status_update in task:
                    yield {
                        "type": "agent_status",
                        "agent_name": agent_name,
                        "status": status_update.dict(),
                        "timestamp": datetime.now().isoformat()
                    }
                    
                    if status_update.current_stage == "completed":
                        agent_results[agent_name] = status_update.intermediate_results
                        
            # 5. å…±è¯†æ„å»ºé˜¶æ®µ
            yield {
                "type": "consensus_building",
                "timestamp": datetime.now().isoformat(),
                "message": "æ„å»ºæ™ºèƒ½ä½“å…±è¯†",
                "participating_agents": list(agent_results.keys())
            }
            
            consensus_result = await self._build_consensus_streaming(agent_results)
            async for consensus_update in consensus_result:
                yield consensus_update
                
            # 6. è§„åˆ™å¼•æ“éªŒè¯
            yield {
                "type": "rule_validation",
                "timestamp": datetime.now().isoformat(),
                "message": "åº”ç”¨ä¸“å®¶è§„åˆ™éªŒè¯"
            }
            
            # 7. æœ€ç»ˆç»“æœ
            final_result = self._generate_final_result(agent_results, consensus_result)
            yield {
                "type": "diagnosis_complete",
                "timestamp": datetime.now().isoformat(),
                "result": final_result.dict(),
                "confidence": final_result.confidence_score
            }
            
        except Exception as e:
            yield {
                "type": "diagnosis_error",
                "timestamp": datetime.now().isoformat(),
                "error": str(e),
                "traceback": traceback.format_exc()
            }
            
    async def _execute_agent_with_streaming(self, agent: ReactiveAgent, 
                                           system_data: SystemData) -> AsyncGenerator[StreamingAgentStatus, None]:
        """æµå¼æ‰§è¡Œæ™ºèƒ½ä½“"""
        input_prompt = self._format_system_data_for_agent(agent.name, system_data)
        
        async for status in agent.execute_streaming(input_prompt):
            yield status
            
    def _format_system_data_for_agent(self, agent_name: str, system_data: SystemData) -> str:
        """ä¸ºæ™ºèƒ½ä½“æ ¼å¼åŒ–è¾“å…¥æ•°æ®"""
        if agent_name == "HardwareAnalysisAgent":
            return f"""
è¯·åˆ†æä»¥ä¸‹ç¡¬ä»¶æ•°æ®:
CPU: {system_data.hardware_data.cpu}
å†…å­˜: {system_data.hardware_data.memory}
å­˜å‚¨: {system_data.hardware_data.storage}
æ¸©åº¦: {system_data.hardware_data.temperatures}
ç”µæº: {system_data.hardware_data.power}

è¯·æä¾›ç»“æ„åŒ–çš„JSONè¯Šæ–­ç»“æœã€‚
            """
        elif agent_name == "SystemAnalysisAgent":
            return f"""
è¯·åˆ†æä»¥ä¸‹ç³»ç»Ÿæ•°æ®:
è¿›ç¨‹: {system_data.system_data.processes}
æœåŠ¡: {system_data.system_data.services}
æ—¥å¿—: {system_data.system_data.logs}
æ€§èƒ½: {system_data.system_data.performance}

è¯·æä¾›ç»“æ„åŒ–çš„JSONè¯Šæ–­ç»“æœã€‚
            """
        elif agent_name == "NetworkAnalysisAgent":
            return f"""
è¯·åˆ†æä»¥ä¸‹ç½‘ç»œæ•°æ®:
ç½‘ç»œæ¥å£: {system_data.network_data.interfaces}
è¿æ¥çŠ¶æ€: {system_data.network_data.connections}
å¸¦å®½ä½¿ç”¨: {system_data.network_data.bandwidth}
DNSçŠ¶æ€: {system_data.network_data.dns_status}

è¯·æä¾›ç»“æ„åŒ–çš„JSONè¯Šæ–­ç»“æœã€‚
            """
        else:
            return f"è¯·åˆ†æç³»ç»Ÿæ•°æ®: {system_data}"
            
class DiagnosisRenderer:
    """è¯Šæ–­ç»“æœæ¸²æŸ“å™¨"""
    
    def __init__(self):
        self.current_agents = {}
        self.diagnosis_timeline = []
        
    def render_agent_status(self, status: StreamingAgentStatus) -> Dict[str, Any]:
        """æ¸²æŸ“æ™ºèƒ½ä½“çŠ¶æ€"""
        self.current_agents[status.agent_name] = status
        
        return {
            "agent_name": status.agent_name,
            "display_name": self._get_agent_display_name(status.agent_name),
            "stage": status.current_stage,
            "stage_display": self._get_stage_display_name(status.current_stage),
            "progress": status.progress_percentage,
            "status_icon": self._get_status_icon(status.current_stage),
            "status_color": self._get_status_color(status.current_stage),
            "current_action": status.current_action,
            "tool_calls_count": len(status.tool_calls),
            "has_results": bool(status.intermediate_results),
            "timestamp": status.timestamp
        }
        
    def render_diagnosis_timeline(self) -> List[Dict[str, Any]]:
        """æ¸²æŸ“è¯Šæ–­æ—¶é—´çº¿"""
        timeline_items = []
        
        for item in self.diagnosis_timeline:
            timeline_items.append({
                "timestamp": item["timestamp"],
                "type": item["type"],
                "title": self._get_timeline_title(item),
                "description": self._get_timeline_description(item),
                "icon": self._get_timeline_icon(item["type"]),
                "color": self._get_timeline_color(item["type"])
            })
            
        return timeline_items
        
    def render_agent_execution_graph(self) -> Dict[str, Any]:
        """æ¸²æŸ“æ™ºèƒ½ä½“æ‰§è¡Œå›¾"""
        nodes = []
        edges = []
        
        # ç”ŸæˆèŠ‚ç‚¹
        for agent_name, status in self.current_agents.items():
            nodes.append({
                "id": agent_name,
                "label": self._get_agent_display_name(agent_name),
                "status": status.current_stage,
                "progress": status.progress_percentage,
                "color": self._get_status_color(status.current_stage),
                "size": self._calculate_node_size(status)
            })
            
        # ç”Ÿæˆè¿æ¥
        agent_names = list(self.current_agents.keys())
        for i, source in enumerate(agent_names):
            for target in agent_names[i+1:]:
                edges.append({
                    "source": source,
                    "target": target,
                    "type": "collaboration",
                    "weight": self._calculate_collaboration_weight(source, target)
                })
                
        return {
            "nodes": nodes,
            "edges": edges,
            "layout": "force",
            "timestamp": datetime.now().isoformat()
        }
        
    def _get_agent_display_name(self, agent_name: str) -> str:
        """è·å–æ™ºèƒ½ä½“æ˜¾ç¤ºåç§°"""
        display_names = {
            "HardwareAnalysisAgent": "ç¡¬ä»¶åˆ†ææ™ºèƒ½ä½“",
            "SystemAnalysisAgent": "ç³»ç»Ÿåˆ†ææ™ºèƒ½ä½“",
            "NetworkAnalysisAgent": "ç½‘ç»œåˆ†ææ™ºèƒ½ä½“",
            "ValidationAgent": "éªŒè¯æ™ºèƒ½ä½“"
        }
        return display_names.get(agent_name, agent_name)
        
    def _get_stage_display_name(self, stage: str) -> str:
        """è·å–é˜¶æ®µæ˜¾ç¤ºåç§°"""
        stage_names = {
            "idle": "ç©ºé—²",
            "starting": "å¯åŠ¨ä¸­",
            "analyzing": "åˆ†æä¸­",
            "tool_calling": "å·¥å…·è°ƒç”¨",
            "reasoning": "æ¨ç†ä¸­",
            "validating": "éªŒè¯ä¸­",
            "completed": "å·²å®Œæˆ",
            "error": "é”™è¯¯"
        }
        return stage_names.get(stage, stage)
        
    def _get_status_icon(self, stage: str) -> str:
        """è·å–çŠ¶æ€å›¾æ ‡"""
        icons = {
            "idle": "â¸ï¸",
            "starting": "â–¶ï¸",
            "analyzing": "ğŸ”",
            "tool_calling": "ğŸ› ï¸",
            "reasoning": "ğŸ§ ",
            "validating": "âœ…",
            "completed": "ğŸ",
            "error": "âŒ"
        }
        return icons.get(stage, "â“")
        
    def _get_status_color(self, stage: str) -> str:
        """è·å–çŠ¶æ€é¢œè‰²"""
        colors = {
            "idle": "#6c757d",
            "starting": "#ffc107",
            "analyzing": "#17a2b8",
            "tool_calling": "#fd7e14",
            "reasoning": "#6f42c1",
            "validating": "#20c997",
            "completed": "#28a745",
            "error": "#dc3545"
        }
        return colors.get(stage, "#6c757d")
```
    def __init__(self):
        self.agents = {
            'hardware': HardwareAnalysisAgent(),
            'system': SystemAnalysisAgent(),
            'network': NetworkAnalysisAgent(),
            'validator': ValidationAgent()
        }
        self.rule_engine = ExpertRuleEngine()
        self.confidence_threshold = 0.7
        self.audit_logger = AuditLogger()
        
    def diagnose_with_consensus(self, data: SystemData) -> DiagnosisResult:
        """å¤šæ™ºèƒ½ä½“å…±è¯†è¯Šæ–­"""
        # 1. æ•°æ®éªŒè¯
        if not self.validate_input_data(data):
            return self.fallback_diagnosis(data)
            
        # 2. å¤šæ™ºèƒ½ä½“å¹¶è¡Œåˆ†æ
        agent_results = {}
        for agent_name, agent in self.agents.items():
            try:
                result = agent.analyze(data)
                agent_results[agent_name] = result
                self.audit_logger.log_agent_result(agent_name, result)
            except Exception as e:
                logger.error(f"æ™ºèƒ½ä½“ {agent_name} åˆ†æå¤±è´¥: {e}")
                agent_results[agent_name] = None
                
        # 3. äº¤å‰éªŒè¯
        validated_results = self.cross_validate_results(agent_results)
        
        # 4. å…±è¯†å†³ç­–
        consensus_result = self.build_consensus(validated_results)
        
        # 5. ç½®ä¿¡åº¦è¯„ä¼°
        confidence_score = self.calculate_confidence(consensus_result, validated_results)
        
        # 6. è§„åˆ™å¼•æ“éªŒè¯
        if confidence_score < self.confidence_threshold:
            rule_result = self.rule_engine.validate_result(consensus_result, data)
            consensus_result = self.merge_ai_rule_results(consensus_result, rule_result)
            
        # 7. å®¡è®¡è®°å½•
        self.audit_logger.log_final_result(consensus_result, confidence_score)
        
        return DiagnosisResult(
            result=consensus_result,
            confidence=confidence_score,
            reasoning_path=self.audit_logger.get_reasoning_path(),
            validation_status=ValidationStatus.VALIDATED
        )
        
    def cross_validate_results(self, agent_results: Dict) -> Dict:
        """äº¤å‰éªŒè¯æ™ºèƒ½ä½“ç»“æœ"""
        validated = {}
        
        for agent_name, result in agent_results.items():
            if result is None:
                continue
                
            # ä¸å…¶ä»–æ™ºèƒ½ä½“ç»“æœäº¤å‰éªŒè¯
            validation_score = 0
            validators = [r for name, r in agent_results.items() 
                         if name != agent_name and r is not None]
                         
            for validator_result in validators:
                similarity = self.calculate_result_similarity(result, validator_result)
                validation_score += similarity
                
            if validators:
                validation_score /= len(validators)
                
            validated[agent_name] = {
                'result': result,
                'validation_score': validation_score
            }
            
        return validated
        
    def build_consensus(self, validated_results: Dict) -> ConsensusResult:
        """æ„å»ºå…±è¯†ç»“æœ"""
        # æƒé‡æŠ•ç¥¨æœºåˆ¶
        issue_votes = defaultdict(list)
        recommendation_votes = defaultdict(list)
        
        for agent_name, data in validated_results.items():
            result = data['result']
            weight = data['validation_score']
            
            for issue in result.issues:
                issue_votes[issue.category].append({
                    'issue': issue,
                    'weight': weight,
                    'agent': agent_name
                })
                
            for rec in result.recommendations:
                recommendation_votes[rec.category].append({
                    'recommendation': rec,
                    'weight': weight,
                    'agent': agent_name
                })
                
        # è®¡ç®—åŠ æƒå…±è¯†
        consensus_issues = self.calculate_weighted_consensus(issue_votes)
        consensus_recommendations = self.calculate_weighted_consensus(recommendation_votes)
        
        return ConsensusResult(
            issues=consensus_issues,
            recommendations=consensus_recommendations,
            participating_agents=list(validated_results.keys())
        )
```

## æ ¸å¿ƒç»„ä»¶è®¾è®¡

### 1. è¯Šæ–­ç®¡ç†å™¨ (DiagnosticManager)

**èŒè´£**: æ•´ä½“è¯Šæ–­æµç¨‹æ§åˆ¶å’Œç»“æœç®¡ç†

```python
class DiagnosticManager:
    def __init__(self):
        self.agent_manager = AgentManager()
        self.model_manager = ModelManager()
        self.collectors = {}
        
    def start_diagnosis(self) -> DiagnosticResult
    def get_diagnosis_status(self) -> DiagnosticStatus
    def stop_diagnosis(self) -> None
```

**å…³é”®æ–¹æ³•**:
- `start_diagnosis()`: å¯åŠ¨å®Œæ•´è¯Šæ–­æµç¨‹
- `get_realtime_metrics()`: è·å–å®æ—¶ç³»ç»ŸæŒ‡æ ‡
- `generate_report()`: ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š

### 2. æ™ºèƒ½ä½“ç®¡ç†å™¨ (AgentManager)

**èŒè´£**: ç®¡ç†å¤šä¸ªä¸“ä¸šåŒ–æ™ºèƒ½ä½“çš„ååŒå·¥ä½œ

```python
class AgentManager:
    def __init__(self):
        self.hardware_agent = HardwareAnalysisAgent()
        self.system_agent = SystemAnalysisAgent()
        self.network_agent = NetworkAnalysisAgent()
        self.coordinator_agent = CoordinatorAgent()
        self.langgraph_executor = LangGraphExecutor()
        
    def execute_collaborative_diagnosis(self) -> CollaborativeResult
```

**æ™ºèƒ½ä½“ç±»å‹**:
- **ç¡¬ä»¶åˆ†ææ™ºèƒ½ä½“**: CPUã€å†…å­˜ã€ç£ç›˜ã€æ¸©åº¦åˆ†æ
- **ç³»ç»Ÿåˆ†ææ™ºèƒ½ä½“**: è¿›ç¨‹ã€æœåŠ¡ã€æ—¥å¿—åˆ†æ
- **ç½‘ç»œåˆ†ææ™ºèƒ½ä½“**: è¿æ¥ã€å¸¦å®½ã€DNSåˆ†æ
- **åè°ƒæ™ºèƒ½ä½“**: ç»“æœæ•´åˆå’Œå»ºè®®ç”Ÿæˆ

### 3. æ¨¡å‹ç®¡ç†å™¨ (ModelManager)

**èŒè´£**: AIæ¨¡å‹çš„ä¸‹è½½ã€åŠ è½½å’Œç®¡ç†

```python
class ModelManager:
    def __init__(self):
        self.model_path = "models/qwen3-0.6b"
        self.model = None
        self.tokenizer = None
        
    def download_model(self) -> bool
    def load_model(self) -> bool
    def is_model_available(self) -> bool
```

**åŠŸèƒ½ç‰¹æ€§**:
- è‡ªåŠ¨æ£€æµ‹æ¨¡å‹æ˜¯å¦å­˜åœ¨
- ä»HuggingFaceè‡ªåŠ¨ä¸‹è½½Qwen3-0.6B
- æ¨¡å‹ç‰ˆæœ¬ç®¡ç†å’Œæ›´æ–°
- å†…å­˜ä¼˜åŒ–åŠ è½½

### 4. æ•°æ®æ”¶é›†å™¨ç»„ä»¶

#### ç³»ç»Ÿä¿¡æ¯æ”¶é›†å™¨ (SystemInfoCollector)
```python
class SystemInfoCollector:
    def get_cpu_info(self) -> CPUInfo
    def get_memory_info(self) -> MemoryInfo
    def get_disk_info(self) -> DiskInfo
    def get_process_info(self) -> List[ProcessInfo]
    def get_system_logs(self) -> List[LogEntry]
```

#### ç½‘ç»œä¿¡æ¯æ”¶é›†å™¨ (NetworkInfoCollector)
```python
class NetworkInfoCollector:
    def get_network_interfaces(self) -> List[NetworkInterface]
    def test_connectivity(self) -> ConnectivityTest
    def get_bandwidth_usage(self) -> BandwidthInfo
    def check_dns_resolution(self) -> DNSTest
```

#### ç¡¬ä»¶ä¿¡æ¯æ”¶é›†å™¨ (HardwareInfoCollector)
```python
class HardwareInfoCollector:
    def get_hardware_specs(self) -> HardwareSpecs
    def get_temperature_sensors(self) -> List[TemperatureSensor]
    def get_power_status(self) -> PowerStatus
    def get_storage_health(self) -> StorageHealth
```

### 5. LangGraphå·¥ä½œæµå¼•æ“

**å·¥ä½œæµå®šä¹‰**:
```python
class DiagnosticWorkflow:
    def create_workflow(self) -> StateGraph:
        workflow = StateGraph(DiagnosticState)
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("collect_data", self.collect_data_node)
        workflow.add_node("hardware_analysis", self.hardware_analysis_node)
        workflow.add_node("system_analysis", self.system_analysis_node)
        workflow.add_node("network_analysis", self.network_analysis_node)
        workflow.add_node("coordinate_results", self.coordinate_results_node)
        workflow.add_node("generate_report", self.generate_report_node)
        
        # å®šä¹‰è¾¹å’Œæ¡ä»¶è·¯ç”±
        workflow.add_edge(START, "collect_data")
        workflow.add_conditional_edges(
            "collect_data",
            self.route_analysis,
            {
                "hardware": "hardware_analysis",
                "system": "system_analysis", 
                "network": "network_analysis"
            }
        )
```

## å·¥å…·è°ƒç”¨ç³»ç»Ÿ

### å·¥å…·å®šä¹‰æ¶æ„
```python
class ToolRegistry:
    def __init__(self):
        self.system_tools = SystemTools()
        self.network_tools = NetworkTools()
        self.file_tools = FileTools()
        
    def get_available_tools(self) -> List[Tool]
```

### ç³»ç»Ÿå·¥å…·é›†
- **è¿›ç¨‹ç®¡ç†**: æŸ¥çœ‹ã€ç»ˆæ­¢è¿›ç¨‹
- **æœåŠ¡æ§åˆ¶**: å¯åŠ¨ã€åœæ­¢ç³»ç»ŸæœåŠ¡
- **æ€§èƒ½ç›‘æ§**: CPUã€å†…å­˜å®æ—¶ç›‘æ§
- **æ—¥å¿—åˆ†æ**: ç³»ç»Ÿæ—¥å¿—æŸ¥çœ‹å’Œåˆ†æ

### ç½‘ç»œå·¥å…·é›†
- **è¿æ¥æµ‹è¯•**: ping, traceroute
- **ç«¯å£æ‰«æ**: æ£€æµ‹å¼€æ”¾ç«¯å£
- **å¸¦å®½æµ‹è¯•**: ç½‘ç»œé€Ÿåº¦æµ‹è¯•
- **DNSè¯Šæ–­**: DNSè§£ææµ‹è¯•

### æ–‡ä»¶å·¥å…·é›†
- **ç£ç›˜åˆ†æ**: ç£ç›˜ä½¿ç”¨æƒ…å†µ
- **æ–‡ä»¶æœç´¢**: æŸ¥æ‰¾ç‰¹å®šæ–‡ä»¶
- **æƒé™æ£€æŸ¥**: æ–‡ä»¶æƒé™éªŒè¯

## GUIç•Œé¢è®¾è®¡

### ä¸»ç•Œé¢å¸ƒå±€
```mermaid
graph TD
    A[ä¸»çª—å£]
    B[å·¥å…·æ ]
    C[å·¦ä¾§é¢æ¿]
    D[å³ä¾§é¢æ¿]
    E[åº•éƒ¨é¢æ¿]
    
    C1[ç³»ç»Ÿæ¦‚è§ˆ]
    C2[ç¡¬ä»¶çŠ¶æ€]
    C3[ç½‘ç»œçŠ¶æ€]
    
    D1[è¯Šæ–­ç»“æœ]
    D2[AIå¯¹è¯]
    
    E1[æ“ä½œæ—¥å¿—]
    E2[çŠ¶æ€æ ]
    
    A --> B
    A --> C
    A --> D
    A --> E
    
    C --> C1
    C --> C2
    C --> C3
    
    D --> D1
    D --> D2
    
    E --> E1
    E --> E2
```

### ç•Œé¢ç»„ä»¶

#### 1. ç³»ç»Ÿæ¦‚è§ˆé¢æ¿
- å®æ—¶CPUã€å†…å­˜ã€ç£ç›˜ä½¿ç”¨ç‡å›¾è¡¨
- ç³»ç»ŸåŸºæœ¬ä¿¡æ¯æ˜¾ç¤º
- è¿è¡Œæ—¶é•¿å’Œè´Ÿè½½æŒ‡æ ‡

#### 2. ç¡¬ä»¶çŠ¶æ€é¢æ¿
- ç¡¬ä»¶æ¸©åº¦ç›‘æ§
- é£æ‰‡è½¬é€Ÿæ˜¾ç¤º
- ç”µæ± çŠ¶æ€ï¼ˆç¬”è®°æœ¬ç”µè„‘ï¼‰
- å­˜å‚¨è®¾å¤‡å¥åº·çŠ¶æ€

#### 3. ç½‘ç»œçŠ¶æ€é¢æ¿
- ç½‘ç»œæ¥å£çŠ¶æ€
- å®æ—¶å¸¦å®½ä½¿ç”¨å›¾è¡¨
- è¿æ¥è´¨é‡æµ‹è¯•ç»“æœ
- DNSæœåŠ¡å™¨çŠ¶æ€

#### 4. è¯Šæ–­ç»“æœé¢æ¿
- AIåˆ†æç»“æœå±•ç¤º
- é—®é¢˜ä¼˜å…ˆçº§æ’åº
- è§£å†³æ–¹æ¡ˆå»ºè®®
- å†å²è¯Šæ–­è®°å½•

#### 5. AIå¯¹è¯é¢æ¿
- ä¸AIæ™ºèƒ½ä½“å¯¹è¯ç•Œé¢
- è‡ªç„¶è¯­è¨€é—®é¢˜å’¨è¯¢
- è¯Šæ–­è¿‡ç¨‹å®æ—¶åé¦ˆ

### GUIå®ç°æ¶æ„
```python
from PyQt6.QtWidgets import (
    QApplication, QMainWindow, QWidget, QVBoxLayout, QHBoxLayout,
    QSplitter, QTabWidget, QTextEdit, QLabel, QPushButton,
    QSystemTrayIcon, QMenu, QProgressBar, QTableWidget,
    QGraphicsView, QGroupBox, QFrame
)
from PyQt6.QtCore import QThread, QTimer, pyqtSignal, Qt
from PyQt6.QtGui import QIcon, QPixmap, QPainter
import pyqtgraph as pg
import qdarkstyle

class MainApplication(QMainWindow):
    def __init__(self):
        super().__init__()
        self.diagnostic_manager = DiagnosticManager()
        self.init_ui()
        self.init_tray()
        self.setup_timers()
        
    def init_ui(self):
        """åˆå§‹åŒ–ç”¨æˆ·ç•Œé¢"""
        self.setWindowTitle("ç³»ç»Ÿè¯Šæ–­å·¥å…·")
        self.setGeometry(100, 100, 1200, 800)
        
        # è®¾ç½®ä¸»é¢˜
        self.setStyleSheet(qdarkstyle.load_stylesheet_pyqt6())
        
        # åˆ›å»ºä¸­å¤®ç»„ä»¶
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        
        # ä¸»å¸ƒå±€
        main_layout = QVBoxLayout(central_widget)
        
        # åˆ›å»ºå·¥å…·æ 
        self.create_toolbar()
        
        # åˆ›å»ºä¸»åˆ†å‰²å™¨
        main_splitter = QSplitter(Qt.Orientation.Horizontal)
        main_layout.addWidget(main_splitter)
        
        # å·¦ä¾§é¢æ¿
        self.left_panel = self.create_left_panel()
        main_splitter.addWidget(self.left_panel)
        
        # å³ä¾§é¢æ¿
        self.right_panel = self.create_right_panel()
        main_splitter.addWidget(self.right_panel)
        
        # åº•éƒ¨é¢æ¿
        self.bottom_panel = self.create_bottom_panel()
        main_layout.addWidget(self.bottom_panel)
        
        # è®¾ç½®åˆ†å‰²å™¨æ¯”ä¾‹
        main_splitter.setSizes([400, 800])
        
    def create_toolbar(self):
        """åˆ›å»ºå·¥å…·æ """
        toolbar = self.addToolBar('ä¸»å·¥å…·æ ')
        
        # å¼€å§‹è¯Šæ–­æŒ‰é’®
        self.start_btn = QPushButton('å¼€å§‹è¯Šæ–­')
        self.start_btn.clicked.connect(self.start_diagnosis)
        toolbar.addWidget(self.start_btn)
        
        # åœæ­¢è¯Šæ–­æŒ‰é’®
        self.stop_btn = QPushButton('åœæ­¢è¯Šæ–­')
        self.stop_btn.clicked.connect(self.stop_diagnosis)
        self.stop_btn.setEnabled(False)
        toolbar.addWidget(self.stop_btn)
        
        toolbar.addSeparator()
        
        # è®¾ç½®æŒ‰é’®
        settings_btn = QPushButton('è®¾ç½®')
        settings_btn.clicked.connect(self.open_settings)
        toolbar.addWidget(settings_btn)
        
    def create_left_panel(self) -> QWidget:
        """åˆ›å»ºå·¦ä¾§é¢æ¿"""
        panel = QWidget()
        layout = QVBoxLayout(panel)
        
        # ç³»ç»Ÿæ¦‚è§ˆé¢æ¿
        self.system_overview = SystemOverviewWidget()
        layout.addWidget(self.system_overview)
        
        # ç¡¬ä»¶çŠ¶æ€é¢æ¿
        self.hardware_status = HardwareStatusWidget()
        layout.addWidget(self.hardware_status)
        
        # ç½‘ç»œçŠ¶æ€é¢æ¿
        self.network_status = NetworkStatusWidget()
        layout.addWidget(self.network_status)
        
        return panel
        
    def create_right_panel(self) -> QWidget:
        """åˆ›å»ºå³ä¾§é¢æ¿"""
        panel = QWidget()
        layout = QVBoxLayout(panel)
        
        # åˆ›å»ºå³ä¾§åˆ†å‰²å™¨
        right_splitter = QSplitter(Qt.Orientation.Vertical)
        layout.addWidget(right_splitter)
        
        # è¯Šæ–­ç»“æœé¢æ¿
        self.diagnosis_panel = DiagnosisResultWidget()
        right_splitter.addWidget(self.diagnosis_panel)
        
        # AIå¯¹è¯é¢æ¿
        self.chat_panel = AIChatWidget()
        right_splitter.addWidget(self.chat_panel)
        
        # è®¾ç½®åˆ†å‰²å™¨æ¯”ä¾‹
        right_splitter.setSizes([400, 400])
        
        return panel
        
    def create_bottom_panel(self) -> QWidget:
        """åˆ›å»ºåº•éƒ¨é¢æ¿"""
        panel = QFrame()
        panel.setFrameStyle(QFrame.Shape.StyledPanel)
        panel.setMaximumHeight(150)
        
        layout = QHBoxLayout(panel)
        
        # æ“ä½œæ—¥å¿—
        self.log_widget = LogWidget()
        layout.addWidget(self.log_widget)
        
        return panel
        
    def init_tray(self):
        """åˆå§‹åŒ–ç³»ç»Ÿæ‰˜ç›˜"""
        self.tray_icon = QSystemTrayIcon(self)
        self.tray_icon.setIcon(QIcon('assets/icon.png'))
        
        # æ‰˜ç›˜èœå•
        tray_menu = QMenu()
        
        show_action = tray_menu.addAction('æ˜¾ç¤ºä¸»çª—å£')
        show_action.triggered.connect(self.show)
        
        tray_menu.addSeparator()
        
        quit_action = tray_menu.addAction('é€€å‡º')
        quit_action.triggered.connect(QApplication.instance().quit)
        
        self.tray_icon.setContextMenu(tray_menu)
        self.tray_icon.show()
        
    def setup_timers(self):
        """è®¾ç½®å®šæ—¶å™¨"""
        # å®æ—¶æ•°æ®æ›´æ–°å®šæ—¶å™¨
        self.update_timer = QTimer()
        self.update_timer.timeout.connect(self.update_realtime_data)
        self.update_timer.start(5000)  # 5ç§’æ›´æ–°ä¸€æ¬¡
        
    def start_diagnosis(self):
        """å¼€å§‹è¯Šæ–­"""
        self.start_btn.setEnabled(False)
        self.stop_btn.setEnabled(True)
        
        # åœ¨å•ç‹¬çº¿ç¨‹ä¸­å¯åŠ¨è¯Šæ–­
        self.diagnosis_thread = DiagnosisThread(self.diagnostic_manager)
        self.diagnosis_thread.progress_updated.connect(self.update_diagnosis_progress)
        self.diagnosis_thread.diagnosis_completed.connect(self.on_diagnosis_completed)
        self.diagnosis_thread.start()
        
    def stop_diagnosis(self):
        """åœæ­¢è¯Šæ–­"""
        if hasattr(self, 'diagnosis_thread'):
            self.diagnosis_thread.stop()
            
        self.start_btn.setEnabled(True)
        self.stop_btn.setEnabled(False)
        
    def update_realtime_data(self):
        """æ›´æ–°å®æ—¶æ•°æ®"""
        # æ›´æ–°å„ä¸ªé¢æ¿çš„å®æ—¶æ•°æ®
        self.system_overview.update_data()
        self.hardware_status.update_data()
        self.network_status.update_data()
```

## è·¨å¹³å°æ”¯æŒ

### å¹³å°é€‚é…ç­–ç•¥

#### Windowsæ”¯æŒ
- WMIæ¥å£ç”¨äºç¡¬ä»¶ä¿¡æ¯æ”¶é›†
- Windowsäº‹ä»¶æ—¥å¿—åˆ†æ
- æ³¨å†Œè¡¨å¥åº·æ£€æŸ¥
- WindowsæœåŠ¡çŠ¶æ€ç›‘æ§

#### macOSæ”¯æŒ
- system_profilerå‘½ä»¤é›†æˆ
- Consoleæ—¥å¿—åˆ†æ
- LaunchdæœåŠ¡ç›‘æ§
- ç¡¬ä»¶ä¼ æ„Ÿå™¨è¯»å–

#### Linuxæ”¯æŒ
- /procå’Œ/sysæ–‡ä»¶ç³»ç»Ÿè¯»å–
- systemdæœåŠ¡çŠ¶æ€
- dmesgæ—¥å¿—åˆ†æ
- ç¡¬ä»¶ä¼ æ„Ÿå™¨(lm-sensors)

### å¹³å°æŠ½è±¡å±‚
```python
class PlatformAdapter:
    @staticmethod
    def get_platform_collector():
        if platform.system() == "Windows":
            return WindowsCollector()
        elif platform.system() == "Darwin":
            return MacOSCollector()
        else:
            return LinuxCollector()
```

## æ•°æ®æ¨¡å‹

### è¯Šæ–­çŠ¶æ€æ¨¡å‹
```python
@dataclass
class DiagnosticState:
    hardware_data: HardwareData
    system_data: SystemData
    network_data: NetworkData
    analysis_results: List[AnalysisResult]
    recommendations: List[Recommendation]
    current_stage: DiagnosticStage
```

### ç¡¬ä»¶ä¿¡æ¯æ¨¡å‹
```python
@dataclass
class HardwareData:
    cpu: CPUInfo
    memory: MemoryInfo
    storage: List[StorageDevice]
    temperatures: List[TemperatureSensor]
    power: PowerInfo
```

### åˆ†æç»“æœæ¨¡å‹
```python
@dataclass
class AnalysisResult:
    category: str
    severity: Severity
    title: str
    description: str
    affected_components: List[str]
    recommendations: List[str]
    confidence: float
```

## é¡¹ç›®ç®¡ç†ä¸ç‰ˆæœ¬æ§åˆ¶

### uvåŒ…ç®¡ç†æ¶æ„

#### é¡¹ç›®ç»“æ„
```
sysgraph/
â”œâ”€â”€ pyproject.toml          # é¡¹ç›®é…ç½®å’Œä¾èµ–å®šä¹‰
â”œâ”€â”€ uv.lock                 # é”å®šçš„ä¾èµ–ç‰ˆæœ¬
â”œâ”€â”€ .python-version         # Pythonç‰ˆæœ¬æŒ‡å®š
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â”œâ”€â”€ src/
â”‚   â””â”€â”€ sysgraph/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ main.py
â”‚       â”œâ”€â”€ core/               # æ ¸å¿ƒæ¨¡å—
â”‚       â”œâ”€â”€ agents/             # æ™ºèƒ½ä½“æ¨¡å—
â”‚       â”œâ”€â”€ collectors/         # æ•°æ®æ”¶é›†å™¨
â”‚       â”œâ”€â”€ gui/                # GUIç•Œé¢
â”‚       â”œâ”€â”€ tools/              # å·¥å…·é›†
â”‚       â”œâ”€â”€ models/             # AIæ¨¡å‹ç®¡ç†
â”‚       â”œâ”€â”€ utils/              # å·¥å…·å‡½æ•°
â”‚       â””â”€â”€ config/             # é…ç½®ç®¡ç†
â”œâ”€â”€ tests/                   # æµ‹è¯•æ–‡ä»¶
â”œâ”€â”€ docs/                    # æ–‡æ¡£
â”œâ”€â”€ scripts/                 # è„šæœ¬æ–‡ä»¶
â””â”€â”€ models/                  # æœ¬åœ°æ¨¡å‹å­˜å‚¨
```

#### pyproject.tomlé…ç½®
```toml
[project]
name = "sysgraph"
version = "1.0.0"
description = "æ™ºèƒ½ç³»ç»Ÿè¯ºæ–­å·¥å…·"
authors = [{name = "Your Name", email = "your.email@example.com"}]
requires-python = ">=3.9"
readme = "README.md"
license = {text = "MIT"}
keywords = ["system", "diagnostics", "ai", "monitoring"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: System Administrators",
    "Topic :: System :: Systems Administration",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
]

dependencies = [
    "langchain>=0.1.0",
    "langgraph>=0.0.40",
    "transformers>=4.35.0",
    "torch>=2.0.0",
    "PyQt6>=6.6.0",
    "PyQt6-Qt6>=6.6.0",
    "pyqtgraph>=0.13.0",
    "qdarkstyle>=3.2.0",
    "qt-material>=2.14",
    "psutil>=5.9.0",
    "requests>=2.31.0",
    "ping3>=4.0.4",
    "netifaces>=0.11.0",
    "huggingface-hub>=0.19.0",
    "pydantic>=2.0.0",
    "pyyaml>=6.0",
    "loguru>=0.7.0",
    "matplotlib>=3.7.0",
    "plotly>=5.17.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.0.0",
    "pytest-cov>=4.0.0",
    "black>=23.0.0",
    "isort>=5.12.0",
    "flake8>=6.0.0",
    "mypy>=1.0.0",
    "pre-commit>=3.0.0",
]
build = [
    "pyinstaller>=5.13.0",
    "cx-freeze>=6.15.0",
]
test = [
    "pytest-xvfb>=3.0.0",  # Linux GUIæµ‹è¯•
    "pytest-qt>=4.2.0",    # GUIç»„ä»¶æµ‹è¯•
]

[project.scripts]
sysgraph = "sysgraph.main:main"
sysgraph-cli = "sysgraph.cli:main"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src/sysgraph"]

[tool.uv]
dev-dependencies = [
    "pytest>=7.0.0",
    "pytest-cov>=4.0.0",
    "black>=23.0.0",
    "isort>=5.12.0",
    "flake8>=6.0.0",
    "mypy>=1.0.0",
]

[tool.black]
line-length = 88
target-version = ['py39']
include = '\.pyi?$'

[tool.isort]
profile = "black"
multi_line_output = 3
line_length = 88

[tool.mypy]
python_version = "3.9"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
```

### ç‰ˆæœ¬æ§åˆ¶ç®¡ç†

#### ç‰ˆæœ¬å·å‘½åçº¦å®š
é‡‡ç”¨è¯­ä¹‰åŒ–ç‰ˆæœ¬å· (Semantic Versioning): `MAJOR.MINOR.PATCH`

- **MAJOR**: ä¸å…¼å®¹çš„APIä¿®æ”¹
- **MINOR**: å‘åå…¼å®¹çš„åŠŸèƒ½æ·»åŠ 
- **PATCH**: å‘åå…¼å®¹çš„é—®é¢˜ä¿®å¤

#### ç‰ˆæœ¬ç®¡ç†å™¨ (VersionManager)
```python
class VersionManager:
    def __init__(self):
        self.current_version = self.get_current_version()
        self.release_checker = ReleaseChecker()
        self.installer = ApplicationInstaller()
        
    def get_current_version(self) -> str:
        """è·å–å½“å‰åº”ç”¨ç¨‹åºç‰ˆæœ¬å·"""
        # ä»åº”ç”¨ç¨‹åºå…ƒæ•°æ®è·å–ç‰ˆæœ¬
        import sysgraph
        return sysgraph.__version__
        
    def check_for_updates(self) -> Optional[ReleaseInfo]:
        """æ£€æŸ¥GitHub Releasesä¸­çš„æ–°ç‰ˆæœ¬"""
        try:
            latest_release = self.release_checker.get_latest_release()
            if self.is_newer_version(latest_release.version, self.current_version):
                return latest_release
            return None
        except Exception as e:
            logger.error(f"æ£€æŸ¥æ›´æ–°å¤±è´¥: {e}")
            return None
        
    def download_release(self, release: ReleaseInfo) -> Optional[str]:
        """ä¸‹è½½å‘å¸ƒç‰ˆæœ¬æ–‡ä»¶"""
        try:
            download_path = self.installer.download_release(release)
            if self.installer.verify_release_integrity(download_path, release.checksum):
                return download_path
            else:
                logger.error("å‘å¸ƒç‰ˆæœ¬æ–‡ä»¶æ ¡éªŒå¤±è´¥")
                return None
        except Exception as e:
            logger.error(f"ä¸‹è½½å‘å¸ƒç‰ˆæœ¬å¤±è´¥: {e}")
            return None
        
    def install_update(self, release_path: str) -> bool:
        """å®‰è£…æ›´æ–°ç‰ˆæœ¬"""
        try:
            # å¤‡ä»½å½“å‰ç‰ˆæœ¬
            backup_path = self.installer.backup_current_version()
            
            # å®‰è£…æ–°ç‰ˆæœ¬
            success = self.installer.install_from_release(release_path)
            
            if success:
                logger.info(f"æˆåŠŸæ›´æ–°åˆ°ç‰ˆæœ¬ {release.version}")
                return True
            else:
                # å®‰è£…å¤±è´¥ï¼Œæ¢å¤å¤‡ä»½
                self.installer.restore_from_backup(backup_path)
                logger.error("å®‰è£…å¤±è´¥ï¼Œå·²æ¢å¤å¤‡ä»½")
                return False
                
        except Exception as e:
            logger.error(f"å®‰è£…æ›´æ–°å¤±è´¥: {e}")
            return False
            
    def rollback_version(self, target_version: str) -> bool:
        """å›æ»šåˆ°æŒ‡å®šç‰ˆæœ¬"""
        backup_versions = self.installer.list_backup_versions()
        if target_version in backup_versions:
            return self.installer.restore_version(target_version)
        else:
            logger.error(f"æœªæ‰¾åˆ°ç‰ˆæœ¬ {target_version} çš„å¤‡ä»½")
            return False
            
    def is_newer_version(self, version1: str, version2: str) -> bool:
        """æ¯”è¾ƒç‰ˆæœ¬å·"""
        from packaging import version
        return version.parse(version1) > version.parse(version2)
```

#### å‘å¸ƒç‰ˆæœ¬æ£€æŸ¥å™¨ (ReleaseChecker)
```python
@dataclass
class ReleaseInfo:
    version: str
    tag_name: str
    release_date: str
    download_url: str
    changelog: str
    is_prerelease: bool
    is_critical: bool
    file_size: int
    checksum: str
    assets: List[ReleaseAsset]
    source: str  # "github" or "gitea"

@dataclass
class ReleaseAsset:
    name: str
    download_url: str
    size: int
    content_type: str
    platform: str  # windows, macos, linux

class ReleaseChecker:
    def __init__(self):
        self.repo_config = self._load_repo_config()
        self.current_platform = self.detect_platform()
        
    def _load_repo_config(self) -> Dict[str, str]:
        """åŠ è½½ä»“åº“é…ç½®"""
        # å¯ä»¥ä»é…ç½®æ–‡ä»¶æˆ–ç¯å¢ƒå˜é‡åŠ è½½
        return {
            "type": "gitea",  # "github" or "gitea"
            "host": "git.example.com",  # Giteaå®ä¾‹åœ°å€
            "owner": "username",
            "repo": "sysgraph",
            "api_token": ""  # å¦‚æœéœ€è¦è®¤è¯
        }
        
    def get_latest_release(self) -> Optional[ReleaseInfo]:
        """è·å–æœ€æ–°çš„ç¨³å®šç‰ˆæœ¬å‘å¸ƒ"""
        if self.repo_config["type"] == "github":
            return self._get_github_release()
        elif self.repo_config["type"] == "gitea":
            return self._get_gitea_release()
        else:
            logger.error(f"ä¸æ”¯æŒçš„ä»“åº“ç±»å‹: {self.repo_config['type']}")
            return None
            
    def _get_github_release(self) -> Optional[ReleaseInfo]:
        """è·å–GitHubæœ€æ–°å‘å¸ƒ"""
        try:
            url = f"https://api.github.com/repos/{self.repo_config['owner']}/{self.repo_config['repo']}/releases/latest"
            headers = self._get_github_headers()
            
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            
            release_data = response.json()
            return self._parse_github_release_data(release_data)
            
        except requests.RequestException as e:
            logger.error(f"è·å–GitHubæœ€æ–°å‘å¸ƒå¤±è´¥: {e}")
            return None
            
    def _get_gitea_release(self) -> Optional[ReleaseInfo]:
        """è·å–Giteaæœ€æ–°å‘å¸ƒ"""
        try:
            host = self.repo_config["host"]
            owner = self.repo_config["owner"]
            repo = self.repo_config["repo"]
            
            url = f"https://{host}/api/v1/repos/{owner}/{repo}/releases/latest"
            headers = self._get_gitea_headers()
            
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            
            release_data = response.json()
            return self._parse_gitea_release_data(release_data)
            
        except requests.RequestException as e:
            logger.error(f"è·å–Giteaæœ€æ–°å‘å¸ƒå¤±è´¥: {e}")
            return None
            
    def _get_github_headers(self) -> Dict[str, str]:
        """è·å–GitHub APIè¯·æ±‚å¤´"""
        headers = {
            "Accept": "application/vnd.github.v3+json",
            "User-Agent": "SysGraph-UpdateChecker/1.0"
        }
        
        if self.repo_config.get("api_token"):
            headers["Authorization"] = f"token {self.repo_config['api_token']}"
            
        return headers
        
    def _get_gitea_headers(self) -> Dict[str, str]:
        """è·å–Gitea APIè¯·æ±‚å¤´"""
        headers = {
            "Accept": "application/json",
            "User-Agent": "SysGraph-UpdateChecker/1.0"
        }
        
        if self.repo_config.get("api_token"):
            headers["Authorization"] = f"token {self.repo_config['api_token']}"
            
        return headers
        
    def _parse_github_release_data(self, release_data: dict) -> ReleaseInfo:
        """è§£æGitHub Releaseæ•°æ®"""
        platform_assets = self.filter_platform_assets(release_data['assets'])
        is_critical = self.is_critical_update(release_data['body'])
        
        return ReleaseInfo(
            version=release_data['tag_name'].lstrip('v'),
            tag_name=release_data['tag_name'],
            release_date=release_data['published_at'],
            download_url=platform_assets[0]['browser_download_url'] if platform_assets else '',
            changelog=release_data['body'],
            is_prerelease=release_data['prerelease'],
            is_critical=is_critical,
            file_size=platform_assets[0]['size'] if platform_assets else 0,
            checksum=self.extract_checksum(release_data['body']),
            assets=self._convert_github_assets(platform_assets),
            source="github"
        )
        
    def _parse_gitea_release_data(self, release_data: dict) -> ReleaseInfo:
        """è§£æGitea Releaseæ•°æ®"""
        platform_assets = self.filter_platform_assets(release_data['assets'])
        is_critical = self.is_critical_update(release_data['body'])
        
        return ReleaseInfo(
            version=release_data['tag_name'].lstrip('v'),
            tag_name=release_data['tag_name'],
            release_date=release_data['published_at'],
            download_url=platform_assets[0]['browser_download_url'] if platform_assets else '',
            changelog=release_data['body'],
            is_prerelease=release_data['prerelease'],
            is_critical=is_critical,
            file_size=platform_assets[0]['size'] if platform_assets else 0,
            checksum=self.extract_checksum(release_data['body']),
            assets=self._convert_gitea_assets(platform_assets),
            source="gitea"
        )
        
    def _convert_github_assets(self, assets: List[dict]) -> List[ReleaseAsset]:
        """è½¬æ¢GitHubèµ„æºæ ¼å¼"""
        return [
            ReleaseAsset(
                name=asset['name'],
                download_url=asset['browser_download_url'],
                size=asset['size'],
                content_type=asset['content_type'],
                platform=self.detect_asset_platform(asset['name'])
            ) for asset in assets
        ]
        
    def _convert_gitea_assets(self, assets: List[dict]) -> List[ReleaseAsset]:
        """è½¬æ¢Giteaèµ„æºæ ¼å¼"""
        return [
            ReleaseAsset(
                name=asset['name'],
                download_url=asset['browser_download_url'],
                size=asset['size'],
                content_type=asset.get('content_type', 'application/octet-stream'),
                platform=self.detect_asset_platform(asset['name'])
            ) for asset in assets
        ]
        
    def get_all_releases(self, limit: int = 10) -> List[ReleaseInfo]:
        """è·å–æ‰€æœ‰å‘å¸ƒç‰ˆæœ¬åˆ—è¡¨"""
        if self.repo_config["type"] == "github":
            return self._get_all_github_releases(limit)
        elif self.repo_config["type"] == "gitea":
            return self._get_all_gitea_releases(limit)
        else:
            return []
            
    def _get_all_github_releases(self, limit: int) -> List[ReleaseInfo]:
        """è·å–æ‰€æœ‰GitHubå‘å¸ƒ"""
        try:
            url = f"https://api.github.com/repos/{self.repo_config['owner']}/{self.repo_config['repo']}/releases"
            headers = self._get_github_headers()
            params = {'per_page': limit}
            
            response = requests.get(url, headers=headers, params=params, timeout=10)
            response.raise_for_status()
            
            releases_data = response.json()
            return [self._parse_github_release_data(release) for release in releases_data
                   if not release['prerelease']]
                   
        except requests.RequestException as e:
            logger.error(f"è·å–GitHubå‘å¸ƒåˆ—è¡¨å¤±è´¥: {e}")
            return []
            
    def _get_all_gitea_releases(self, limit: int) -> List[ReleaseInfo]:
        """è·å–æ‰€æœ‰Giteaå‘å¸ƒ"""
        try:
            host = self.repo_config["host"]
            owner = self.repo_config["owner"]
            repo = self.repo_config["repo"]
            
            url = f"https://{host}/api/v1/repos/{owner}/{repo}/releases"
            headers = self._get_gitea_headers()
            params = {'limit': limit}
            
            response = requests.get(url, headers=headers, params=params, timeout=10)
            response.raise_for_status()
            
            releases_data = response.json()
            return [self._parse_gitea_release_data(release) for release in releases_data
                   if not release['prerelease']]
                   
        except requests.RequestException as e:
            logger.error(f"è·å–Giteaå‘å¸ƒåˆ—è¡¨å¤±è´¥: {e}")
            return []
```

#### åº”ç”¨å®‰è£…å™¨ (ApplicationInstaller)
```python
class ApplicationInstaller:
    def __init__(self):
        self.app_dir = Path.cwd()
        self.backup_dir = self.app_dir / "backups"
        self.download_dir = self.app_dir / "downloads"
        self.backup_dir.mkdir(exist_ok=True)
        self.download_dir.mkdir(exist_ok=True)
        
    def download_release(self, release: ReleaseInfo) -> str:
        """ä¸‹è½½å‘å¸ƒç‰ˆæœ¬æ–‡ä»¶"""
        if not release.download_url:
            raise ValueError("æœªæ‰¾åˆ°é€‚åˆå½“å‰å¹³å°çš„ä¸‹è½½é“¾æ¥")
            
        filename = release.download_url.split('/')[-1]
        file_path = self.download_dir / filename
        
        logger.info(f"å¼€å§‹ä¸‹è½½å‘å¸ƒç‰ˆæœ¬: {release.version}")
        
        response = requests.get(release.download_url, stream=True)
        response.raise_for_status()
        
        total_size = int(response.headers.get('content-length', 0))
        downloaded_size = 0
        
        with open(file_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
                    downloaded_size += len(chunk)
                    
                    # æŠ¥å‘Šä¸‹è½½è¿›åº¦
                    if total_size > 0:
                        progress = (downloaded_size / total_size) * 100
                        logger.debug(f"ä¸‹è½½è¿›åº¦: {progress:.1f}%")
                        
        logger.info(f"ä¸‹è½½å®Œæˆ: {file_path}")
        return str(file_path)
        
    def verify_release_integrity(self, file_path: str, expected_checksum: str) -> bool:
        """éªŒè¯å‘å¸ƒæ–‡ä»¶å®Œæ•´æ€§"""
        if not expected_checksum:
            logger.warning("æœªæä¾›æ ¡éªŒå’Œï¼Œè·³è¿‡éªŒè¯")
            return True
            
        import hashlib
        
        sha256_hash = hashlib.sha256()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                sha256_hash.update(chunk)
                
        calculated_checksum = sha256_hash.hexdigest()
        
        if calculated_checksum.lower() == expected_checksum.lower():
            logger.info("æ–‡ä»¶æ ¡éªŒæˆåŠŸ")
            return True
        else:
            logger.error(f"æ–‡ä»¶æ ¡éªŒå¤±è´¥: æœŸæœ› {expected_checksum}, å®é™… {calculated_checksum}")
            return False
            
    def backup_current_version(self) -> str:
        """å¤‡ä»½å½“å‰ç‰ˆæœ¬"""
        from datetime import datetime
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        current_version = self.get_current_version()
        backup_name = f"backup_{current_version}_{timestamp}"
        backup_path = self.backup_dir / backup_name
        
        logger.info(f"å¼€å§‹å¤‡ä»½å½“å‰ç‰ˆæœ¬åˆ°: {backup_path}")
        
        # å¤‡ä»½å…³é”®æ–‡ä»¶å’Œç›®å½•
        import shutil
        
        backup_path.mkdir(exist_ok=True)
        
        # å¤‡ä»½æ‰§è¡Œæ–‡ä»¶
        executable_files = self.find_executable_files()
        for exe_file in executable_files:
            shutil.copy2(exe_file, backup_path / exe_file.name)
            
        # å¤‡ä»½é…ç½®å’Œæ•°æ®
        config_dirs = ['config', 'data', 'models']
        for config_dir in config_dirs:
            src_dir = self.app_dir / config_dir
            if src_dir.exists():
                dst_dir = backup_path / config_dir
                shutil.copytree(src_dir, dst_dir, ignore_dangling_symlinks=True)
                
        # ä¿å­˜å¤‡ä»½å…ƒæ•°æ®
        backup_info = {
            'version': current_version,
            'timestamp': timestamp,
            'backup_date': datetime.now().isoformat(),
            'files_count': len(list(backup_path.rglob('*')))
        }
        
        with open(backup_path / 'backup_info.json', 'w') as f:
            json.dump(backup_info, f, indent=2)
            
        logger.info(f"å¤‡ä»½å®Œæˆ: {backup_path}")
        return str(backup_path)
        
    def install_from_release(self, release_path: str) -> bool:
        """ä»å‘å¸ƒæ–‡ä»¶å®‰è£…æ–°ç‰ˆæœ¬"""
        release_file = Path(release_path)
        
        if not release_file.exists():
            logger.error(f"å‘å¸ƒæ–‡ä»¶ä¸å­˜åœ¨: {release_path}")
            return False
            
        try:
            # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©å®‰è£…æ–¹æ³•
            if release_file.suffix.lower() == '.exe':
                return self.install_from_exe(release_path)
            elif release_file.suffix.lower() == '.msi':
                return self.install_from_msi(release_path)
            elif release_file.suffix.lower() == '.dmg':
                return self.install_from_dmg(release_path)
            elif release_file.suffix.lower() in ['.tar.gz', '.tgz']:
                return self.install_from_tarball(release_path)
            elif release_file.suffix.lower() == '.deb':
                return self.install_from_deb(release_path)
            elif release_file.suffix.lower() == '.rpm':
                return self.install_from_rpm(release_path)
            else:
                logger.error(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {release_file.suffix}")
                return False
                
        except Exception as e:
            logger.error(f"å®‰è£…å¤±è´¥: {e}")
            return False
            
    def install_from_tarball(self, tarball_path: str) -> bool:
        """ä» tar.gz æ–‡ä»¶å®‰è£…"""
        import tarfile
        
        logger.info(f"ä» tarball å®‰è£…: {tarball_path}")
        
        # åˆ›å»ºä¸´æ—¶è§£å‹ç›®å½•
        extract_dir = self.download_dir / "extract_temp"
        extract_dir.mkdir(exist_ok=True)
        
        try:
            # è§£å‹æ–‡ä»¶
            with tarfile.open(tarball_path, 'r:gz') as tar:
                tar.extractall(extract_dir)
                
            # æŸ¥æ‰¾è§£å‹åçš„æ–‡ä»¶
            extracted_items = list(extract_dir.iterdir())
            if len(extracted_items) == 1 and extracted_items[0].is_dir():
                source_dir = extracted_items[0]
            else:
                source_dir = extract_dir
                
            # å¤åˆ¶æ–‡ä»¶åˆ°åº”ç”¨ç›®å½•
            import shutil
            
            for item in source_dir.iterdir():
                dst_path = self.app_dir / item.name
                
                if item.is_file():
                    shutil.copy2(item, dst_path)
                elif item.is_dir():
                    if dst_path.exists():
                        shutil.rmtree(dst_path)
                    shutil.copytree(item, dst_path)
                    
            # è®¾ç½®æ‰§è¡Œæƒé™
            self.set_executable_permissions()
            
            logger.info("ä» tarball å®‰è£…æˆåŠŸ")
            return True
            
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if extract_dir.exists():
                shutil.rmtree(extract_dir)
                
    def find_executable_files(self) -> List[Path]:
        """æŸ¥æ‰¾å½“å‰ç›®å½•ä¸‹çš„æ‰§è¡Œæ–‡ä»¶"""
        executables = []
        
        # æŸ¥æ‰¾å¸¸è§çš„æ‰§è¡Œæ–‡ä»¶
        patterns = ['*.exe', 'sysgraph', 'sysgraph.exe', 'main.py']
        
        for pattern in patterns:
            executables.extend(self.app_dir.glob(pattern))
            
        return executables
        
    def set_executable_permissions(self):
        """è®¾ç½®æ–‡ä»¶æ‰§è¡Œæƒé™"""
        import stat
        
        executables = self.find_executable_files()
        for exe_file in executables:
            current_permissions = exe_file.stat().st_mode
            new_permissions = current_permissions | stat.S_IEXEC
            exe_file.chmod(new_permissions)
            
    def list_backup_versions(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰å¤‡ä»½ç‰ˆæœ¬"""
        versions = []
        
        for backup_dir in self.backup_dir.iterdir():
            if backup_dir.is_dir():
                info_file = backup_dir / 'backup_info.json'
                if info_file.exists():
                    try:
                        with open(info_file) as f:
                            backup_info = json.load(f)
                            versions.append(backup_info['version'])
                    except (json.JSONDecodeError, KeyError):
                        continue
                        
        return sorted(versions, reverse=True)
        
    def restore_version(self, version: str) -> bool:
        """æ¢å¤åˆ°æŒ‡å®šç‰ˆæœ¬"""
        # æŸ¥æ‰¾å¯¹åº”çš„å¤‡ä»½ç›®å½•
        backup_dirs = [d for d in self.backup_dir.iterdir() 
                      if d.is_dir() and version in d.name]
        
        if not backup_dirs:
            return False
            
        # é€‰æ‹©æœ€æ–°çš„å¤‡ä»½
        backup_dir = sorted(backup_dirs, reverse=True)[0]
        
        logger.info(f"æ¢å¤ç‰ˆæœ¬ {version} ä»å¤‡ä»½: {backup_dir}")
        
        try:
            import shutil
            
            # æ¢å¤æ–‡ä»¶
            for item in backup_dir.iterdir():
                if item.name == 'backup_info.json':
                    continue
                    
                dst_path = self.app_dir / item.name
                
                if item.is_file():
                    shutil.copy2(item, dst_path)
                elif item.is_dir():
                    if dst_path.exists():
                        shutil.rmtree(dst_path)
                    shutil.copytree(item, dst_path)
                    
            logger.info(f"æˆåŠŸæ¢å¤åˆ°ç‰ˆæœ¬ {version}")
            return True
            
        except Exception as e:
            logger.error(f"æ¢å¤ç‰ˆæœ¬å¤±è´¥: {e}")
            return False
```

#### ä¾èµ–æ›´æ–°ç­–ç•¥
```python
class DependencyManager:
    def __init__(self):
        self.uv_manager = UVManager()
        self.update_policy = UpdatePolicy()
        
    def check_dependency_updates(self) -> List[DependencyUpdate]:
        """"**æ£€æŸ¥ä¾èµ–æ›´æ–°"""
        
    def update_dependencies(self, updates: List[str], strategy: str = "minor") -> bool:
        """"**æ›´æ–°ä¾èµ–åŒ…"""
        
    def create_lock_backup(self) -> str:
        """"**åˆ›å»ºé”æ–‡ä»¶å¤‡ä»½"""
        
    def restore_from_backup(self, backup_path: str) -> bool:
        """"**ä»å¤‡ä»½æ¢å¤"""

@dataclass
class DependencyUpdate:
    name: str
    current_version: str
    latest_version: str
    update_type: str  # "patch", "minor", "major"
    security_update: bool
    changelog_url: str
```

#### UVç®¡ç†å™¨å°è£…
```python
class UVManager:
    def __init__(self):
        self.project_root = Path.cwd()
        
    def sync_dependencies(self) -> bool:
        """"**åŒæ­¥ä¾èµ–"""
        result = subprocess.run(["uv", "sync"], capture_output=True)
        return result.returncode == 0
        
    def add_dependency(self, package: str, group: str = "main") -> bool:
        """"**æ·»åŠ ä¾èµ–"""
        cmd = ["uv", "add", package]
        if group != "main":
            cmd.extend(["--group", group])
        result = subprocess.run(cmd, capture_output=True)
        return result.returncode == 0
        
    def remove_dependency(self, package: str) -> bool:
        """"**ç§»é™¤ä¾èµ–"""
        result = subprocess.run(["uv", "remove", package], capture_output=True)
        return result.returncode == 0
        
    def list_outdated(self) -> List[str]:
        """"**åˆ—å‡ºè¿‡æ—¶ä¾èµ–"""
        result = subprocess.run(["uv", "tree", "--outdated"], capture_output=True, text=True)
        return result.stdout.splitlines() if result.returncode == 0 else []
        
    def lock_dependencies(self) -> bool:
        """"**é”å®šä¾èµ–ç‰ˆæœ¬"""
        result = subprocess.run(["uv", "lock"], capture_output=True)
        return result.returncode == 0
```

### è‡ªåŠ¨æ›´æ–°ç³»ç»Ÿ

#### æ›´æ–°ç­–ç•¥é…ç½®
```python
class UpdatePolicy:
    def __init__(self, config: Dict):
        self.auto_check = config.get("auto_check", True)
        self.auto_download = config.get("auto_download", False)
        self.auto_install = config.get("auto_install", False)
        self.check_interval = config.get("check_interval", 24)  # å°æ—¶
        self.allowed_update_types = config.get("allowed_types", ["patch", "minor"])
        self.excluded_packages = config.get("excluded_packages", [])
        
    def should_update(self, update: DependencyUpdate) -> bool:
        """"**åˆ¤æ–­æ˜¯å¦åº”è¯¥æ›´æ–°"""
        if update.name in self.excluded_packages:
            return False
        if update.update_type not in self.allowed_update_types:
            return False
        if update.security_update:  # å®‰å…¨æ›´æ–°ä¼˜å…ˆ
            return True
        return True
```

#### æ›´æ–°è°ƒåº¦å™¨
```python
class UpdateScheduler:
    def __init__(self, policy: UpdatePolicy):
        self.policy = policy
        self.last_check = None
        self.scheduler = BackgroundScheduler()
        
    def start_scheduler(self):
        """"**å¯åŠ¨æ›´æ–°è°ƒåº¦"""
        if self.policy.auto_check:
            self.scheduler.add_job(
                self.check_updates_job,
                'interval',
                hours=self.policy.check_interval
            )
            self.scheduler.start()
            
    def check_updates_job(self):
        """"**å®šæ—¶æ£€æŸ¥æ›´æ–°ä»»åŠ¡"""
        try:
            updates = self.dependency_manager.check_dependency_updates()
            if updates:
                self.notify_updates_available(updates)
                if self.policy.auto_download:
                    self.download_updates(updates)
        except Exception as e:
            logger.error(f"æ£€æŸ¥æ›´æ–°å¤±è´¥: {e}")
```

### æ›´æ–°é€šçŸ¥ç³»ç»Ÿ

#### é€šçŸ¥ç®¡ç†å™¨
```python
class UpdateNotificationManager:
    def __init__(self):
        self.gui_notifier = GUINotifier()
        self.system_notifier = SystemNotifier()
        
    def notify_updates_available(self, updates: List[DependencyUpdate]):
        """"**é€šçŸ¥æ›´æ–°å¯ç”¨"""
        notification = self.create_update_notification(updates)
        
        # GUIé€šçŸ¥
        if self.gui_notifier.is_available():
            self.gui_notifier.show_update_dialog(notification)
            
        # ç³»ç»Ÿé€šçŸ¥
        self.system_notifier.show_notification(
            title="ç³»ç»Ÿè¯Šæ–­å·¥å…·æ›´æ–°",
            message=f"æœ‰ {len(updates)} ä¸ªæ›´æ–°å¯ç”¨",
            urgency="normal"
        )
        
    def create_update_notification(self, updates: List[DependencyUpdate]) -> UpdateNotification:
        """"**åˆ›å»ºæ›´æ–°é€šçŸ¥"""
        security_updates = [u for u in updates if u.security_update]
        regular_updates = [u for u in updates if not u.security_update]
        
        return UpdateNotification(
            total_updates=len(updates),
            security_updates=len(security_updates),
            regular_updates=len(regular_updates),
            details=updates
        )
```

### Gité›†æˆç®¡ç†

#### Gitæ“ä½œå°è£…
```python
class GitManager:
    def __init__(self, repo_path: str):
        self.repo_path = Path(repo_path)
        self.repo = Repo(repo_path)
        
    def get_current_branch(self) -> str:
        """"**è·å–å½“å‰åˆ†æ”¯"""
        return self.repo.active_branch.name
        
    def get_commit_hash(self) -> str:
        """"**è·å–å½“å‰commitå“ˆå¸Œ"""
        return self.repo.head.commit.hexsha[:8]
        
    def check_for_remote_updates(self) -> bool:
        """"**æ£€æŸ¥è¿œç¨‹æ›´æ–°"""
        self.repo.remotes.origin.fetch()
        local_commit = self.repo.head.commit
        remote_commit = self.repo.remotes.origin.refs[self.get_current_branch()].commit
        return local_commit != remote_commit
        
    def pull_updates(self) -> bool:
        """"**æ‹‰å–æ›´æ–°"""
        try:
            self.repo.remotes.origin.pull()
            return True
        except Exception as e:
            logger.error(f"Git pullå¤±è´¥: {e}")
            return False
            
    def create_backup_branch(self) -> str:
        """"**åˆ›å»ºå¤‡ä»½åˆ†æ”¯"""
        backup_name = f"backup-{datetime.now().strftime('%Y%m%d-%H%M%S')}"
        backup_branch = self.repo.create_head(backup_name)
        return backup_name
```

## é…ç½®ç®¡ç†æ¨¡å—

### é…ç½®ç®¡ç†æ¶æ„

#### é…ç½®ç®¡ç†å™¨ (ConfigurationManager)
```python
from typing import Any, Dict, Optional, Union
from pathlib import Path
import json
from dataclasses import dataclass, asdict
from enum import Enum

class ConfigScope(Enum):
    """"**é…ç½®ä½œç”¨åŸŸ"""
    SYSTEM = "system"        # ç³»ç»Ÿçº§é…ç½®
    USER = "user"            # ç”¨æˆ·çº§é…ç½®
    APPLICATION = "app"      # åº”ç”¨çº§é…ç½®
    RUNTIME = "runtime"      # è¿è¡Œæ—¶é…ç½®

@dataclass
class ConfigItem:
    """"**é…ç½®é¡¹å®šä¹‰"""
    key: str
    value: Any
    default_value: Any
    description: str
    value_type: type
    scope: ConfigScope
    is_sensitive: bool = False
    validation_func: Optional[callable] = None
    requires_restart: bool = False
    
class ConfigurationManager:
    """"**ç»Ÿä¸€é…ç½®ç®¡ç†å™¨"""
    
    def __init__(self):
        self.config_dir = Path.home() / ".sysgraph"
        self.config_dir.mkdir(exist_ok=True)
        
        self.config_files = {
            ConfigScope.SYSTEM: self.config_dir / "system.json",
            ConfigScope.USER: self.config_dir / "user.json", 
            ConfigScope.APPLICATION: self.config_dir / "app.json",
            ConfigScope.RUNTIME: self.config_dir / "runtime.json"
        }
        
        self.config_cache = {}
        self.config_schema = self._init_config_schema()
        self.change_listeners = []
        
        # åˆå§‹åŒ–é…ç½®
        self._load_all_configs()
        self._apply_default_configs()
        
    def _init_config_schema(self) -> Dict[str, ConfigItem]:
        """åˆå§‹åŒ–é…ç½®æ¨¡å¼"""
        return {
            # åº”ç”¨åŸºç¡€é…ç½®
            "app.name": ConfigItem(
                key="app.name",
                value="ç³»ç»Ÿè¯Šæ–­å·¥å…·",
                default_value="ç³»ç»Ÿè¯Šæ–­å·¥å…·",
                description="åº”ç”¨ç¨‹åºåç§°",
                value_type=str,
                scope=ConfigScope.APPLICATION
            ),
            "app.version": ConfigItem(
                key="app.version",
                value="1.0.0",
                default_value="1.0.0",
                description="åº”ç”¨ç¨‹åºç‰ˆæœ¬",
                value_type=str,
                scope=ConfigScope.APPLICATION
            ),
            "app.language": ConfigItem(
                key="app.language",
                value="zh-CN",
                default_value="zh-CN",
                description="ç•Œé¢è¯­è¨€",
                value_type=str,
                scope=ConfigScope.USER,
                validation_func=lambda x: x in ["zh-CN", "en-US"]
            ),
            
            # AIæ¨¡å‹é…ç½®
            "model.name": ConfigItem(
                key="model.name",
                value="Qwen/Qwen3-0.6B",
                default_value="Qwen/Qwen3-0.6B",
                description="AIæ¨¡å‹åç§°",
                value_type=str,
                scope=ConfigScope.APPLICATION
            ),
            "model.local_path": ConfigItem(
                key="model.local_path",
                value="./models/qwen3-0.6b",
                default_value="./models/qwen3-0.6b",
                description="æœ¬åœ°æ¨¡å‹è·¯å¾„",
                value_type=str,
                scope=ConfigScope.APPLICATION
            ),
            "model.auto_download": ConfigItem(
                key="model.auto_download",
                value=True,
                default_value=True,
                description="è‡ªåŠ¨ä¸‹è½½æ¨¡å‹",
                value_type=bool,
                scope=ConfigScope.USER
            ),
            "model.device": ConfigItem(
                key="model.device",
                value="auto",
                default_value="auto",
                description="è®¡ç®—è®¾å¤‡ (auto/cpu/cuda)",
                value_type=str,
                scope=ConfigScope.USER,
                validation_func=lambda x: x in ["auto", "cpu", "cuda"]
            ),
            
            # è¯Šæ–­é…ç½®
            "diagnosis.auto_start": ConfigItem(
                key="diagnosis.auto_start",
                value=False,
                default_value=False,
                description="å¯åŠ¨æ—¶è‡ªåŠ¨å¼€å§‹è¯Šæ–­",
                value_type=bool,
                scope=ConfigScope.USER
            ),
            "diagnosis.scan_interval": ConfigItem(
                key="diagnosis.scan_interval",
                value=300,
                default_value=300,
                description="è¯Šæ–­é—´éš”ï¼ˆç§’ï¼‰",
                value_type=int,
                scope=ConfigScope.USER,
                validation_func=lambda x: 60 <= x <= 3600
            ),
            "diagnosis.enable_realtime": ConfigItem(
                key="diagnosis.enable_realtime",
                value=True,
                default_value=True,
                description="å¯ç”¨å®æ—¶ç›‘æ§",
                value_type=bool,
                scope=ConfigScope.USER
            ),
            "diagnosis.confidence_threshold": ConfigItem(
                key="diagnosis.confidence_threshold",
                value=0.7,
                default_value=0.7,
                description="AIè¯Šæ–­ç½®ä¿¡åº¦é˜ˆå€¼",
                value_type=float,
                scope=ConfigScope.APPLICATION,
                validation_func=lambda x: 0.0 <= x <= 1.0
            ),
            
            # æ™ºèƒ½ä½“é…ç½®
            "agents.hardware_agent.enabled": ConfigItem(
                key="agents.hardware_agent.enabled",
                value=True,
                default_value=True,
                description="å¯ç”¨ç¡¬ä»¶åˆ†ææ™ºèƒ½ä½“",
                value_type=bool,
                scope=ConfigScope.USER
            ),
            "agents.hardware_agent.priority": ConfigItem(
                key="agents.hardware_agent.priority",
                value="high",
                default_value="high",
                description="ç¡¬ä»¶åˆ†ææ™ºèƒ½ä½“ä¼˜å…ˆçº§",
                value_type=str,
                scope=ConfigScope.USER,
                validation_func=lambda x: x in ["low", "medium", "high"]
            ),
            
            # GUIé…ç½®
            "gui.theme": ConfigItem(
                key="gui.theme",
                value="dark",
                default_value="dark",
                description="ç•Œé¢ä¸»é¢˜",
                value_type=str,
                scope=ConfigScope.USER,
                validation_func=lambda x: x in ["light", "dark", "auto"]
            ),
            "gui.window_width": ConfigItem(
                key="gui.window_width",
                value=1200,
                default_value=1200,
                description="çª—å£å®½åº¦",
                value_type=int,
                scope=ConfigScope.USER,
                validation_func=lambda x: 800 <= x <= 3840
            ),
            "gui.window_height": ConfigItem(
                key="gui.window_height",
                value=800,
                default_value=800,
                description="çª—å£é«˜åº¦",
                value_type=int,
                scope=ConfigScope.USER,
                validation_func=lambda x: 600 <= x <= 2160
            ),
            "gui.auto_refresh_interval": ConfigItem(
                key="gui.auto_refresh_interval",
                value=5,
                default_value=5,
                description="ç•Œé¢åˆ·æ–°é—´éš”ï¼ˆç§’ï¼‰",
                value_type=int,
                scope=ConfigScope.USER,
                validation_func=lambda x: 1 <= x <= 60
            ),
            
            # æ›´æ–°é…ç½®
            "update.auto_check": ConfigItem(
                key="update.auto_check",
                value=True,
                default_value=True,
                description="è‡ªåŠ¨æ£€æŸ¥æ›´æ–°",
                value_type=bool,
                scope=ConfigScope.USER
            ),
            "update.auto_download": ConfigItem(
                key="update.auto_download",
                value=False,
                default_value=False,
                description="è‡ªåŠ¨ä¸‹è½½æ›´æ–°",
                value_type=bool,
                scope=ConfigScope.USER
            ),
            "update.check_interval": ConfigItem(
                key="update.check_interval",
                value=24,
                default_value=24,
                description="æ›´æ–°æ£€æŸ¥é—´éš”ï¼ˆå°æ—¶ï¼‰",
                value_type=int,
                scope=ConfigScope.USER,
                validation_func=lambda x: 1 <= x <= 168
            ),
            "update.backup_before_update": ConfigItem(
                key="update.backup_before_update",
                value=True,
                default_value=True,
                description="æ›´æ–°å‰å¤‡ä»½",
                value_type=bool,
                scope=ConfigScope.USER
            ),
            
            # æ—¥å¿—é…ç½®
            "logging.level": ConfigItem(
                key="logging.level",
                value="INFO",
                default_value="INFO",
                description="æ—¥å¿—çº§åˆ«",
                value_type=str,
                scope=ConfigScope.APPLICATION,
                validation_func=lambda x: x in ["DEBUG", "INFO", "WARNING", "ERROR"]
            ),
            "logging.max_file_size": ConfigItem(
                key="logging.max_file_size",
                value="10MB",
                default_value="10MB",
                description="æ—¥å¿—æ–‡ä»¶æœ€å¤§å¤§å°",
                value_type=str,
                scope=ConfigScope.APPLICATION
            ),
            "logging.retention_days": ConfigItem(
                key="logging.retention_days",
                value=30,
                default_value=30,
                description="æ—¥å¿—ä¿ç•™å¤©æ•°",
                value_type=int,
                scope=ConfigScope.APPLICATION,
                validation_func=lambda x: 1 <= x <= 365
            )
        }
        
    def get(self, key: str, default: Any = None) -> Any:
        """è·å–é…ç½®å€¼"""
        if key in self.config_schema:
            config_item = self.config_schema[key]
            scope = config_item.scope
            
            # ä»ç¼“å­˜ä¸­è·å–
            if scope in self.config_cache and key in self.config_cache[scope]:
                return self.config_cache[scope][key]
                
            # è¿”å›é»˜è®¤å€¼
            return config_item.default_value
            
        return default
        
    def set(self, key: str, value: Any, persist: bool = True) -> bool:
        """è®¾ç½®é…ç½®å€¼"""
        if key not in self.config_schema:
            logger.warning(f"æœªçŸ¥çš„é…ç½®é¡¹: {key}")
            return False
            
        config_item = self.config_schema[key]
        
        # ç±»å‹éªŒè¯
        if not isinstance(value, config_item.value_type):
            try:
                value = config_item.value_type(value)
            except (ValueError, TypeError):
                logger.error(f"é…ç½®å€¼ç±»å‹é”™è¯¯: {key} = {value}")
                return False
                
        # è‡ªå®šä¹‰éªŒè¯
        if config_item.validation_func and not config_item.validation_func(value):
            logger.error(f"é…ç½®å€¼éªŒè¯å¤±è´¥: {key} = {value}")
            return False
            
        # æ›´æ–°ç¼“å­˜
        scope = config_item.scope
        if scope not in self.config_cache:
            self.config_cache[scope] = {}
            
        old_value = self.config_cache[scope].get(key)
        self.config_cache[scope][key] = value
        
        # æŒä¹…åŒ–å­˜å‚¨
        if persist:
            self._save_config(scope)
            
        # é€šçŸ¥å˜æ›´ç›‘å¬å™¨
        self._notify_config_change(key, old_value, value)
        
        logger.info(f"é…ç½®å·²æ›´æ–°: {key} = {value}")
        return True
        
    def get_config_by_scope(self, scope: ConfigScope) -> Dict[str, Any]:
        """è·å–æŒ‡å®šä½œç”¨åŸŸçš„æ‰€æœ‰é…ç½®"""
        result = {}
        for key, config_item in self.config_schema.items():
            if config_item.scope == scope:
                result[key] = self.get(key)
        return result
        
    def reset_to_default(self, key: str) -> bool:
        """é‡ç½®é…ç½®ä¸ºé»˜è®¤å€¼"""
        if key in self.config_schema:
            default_value = self.config_schema[key].default_value
            return self.set(key, default_value)
        return False
        
    def export_config(self, scope: ConfigScope = None) -> Dict[str, Any]:
        """å¯¼å‡ºé…ç½®"""
        if scope:
            return self.get_config_by_scope(scope)
        else:
            result = {}
            for scope_enum in ConfigScope:
                result[scope_enum.value] = self.get_config_by_scope(scope_enum)
            return result
            
    def import_config(self, config_data: Dict[str, Any], scope: ConfigScope = None) -> bool:
        """å¯¼å…¥é…ç½®"""
        try:
            if scope:
                # å¯¼å…¥æŒ‡å®šä½œç”¨åŸŸçš„é…ç½®
                for key, value in config_data.items():
                    if key in self.config_schema and self.config_schema[key].scope == scope:
                        self.set(key, value, persist=False)
            else:
                # å¯¼å…¥æ‰€æœ‰é…ç½®
                for scope_name, scope_config in config_data.items():
                    try:
                        scope_enum = ConfigScope(scope_name)
                        for key, value in scope_config.items():
                            if key in self.config_schema:
                                self.set(key, value, persist=False)
                    except ValueError:
                        logger.warning(f"æœªçŸ¥çš„é…ç½®ä½œç”¨åŸŸ: {scope_name}")
                        
            # æ‰¹é‡ä¿å­˜
            for scope_enum in ConfigScope:
                self._save_config(scope_enum)
                
            logger.info("é…ç½®å¯¼å…¥æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"é…ç½®å¯¼å…¥å¤±è´¥: {e}")
            return False
            
    def add_change_listener(self, listener: callable):
        """æ·»åŠ é…ç½®å˜æ›´ç›‘å¬å™¨"""
        self.change_listeners.append(listener)
        
    def remove_change_listener(self, listener: callable):
        """ç§»é™¤é…ç½®å˜æ›´ç›‘å¬å™¨"""
        if listener in self.change_listeners:
            self.change_listeners.remove(listener)
            
    def _load_all_configs(self):
        """åŠ è½½æ‰€æœ‰é…ç½®æ–‡ä»¶"""
        for scope, config_file in self.config_files.items():
            if config_file.exists():
                try:
                    with open(config_file, 'r', encoding='utf-8') as f:
                        config_data = json.load(f)
                        self.config_cache[scope] = config_data
                        logger.debug(f"åŠ è½½é…ç½®æ–‡ä»¶: {config_file}")
                except (json.JSONDecodeError, IOError) as e:
                    logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥ {config_file}: {e}")
                    
    def _save_config(self, scope: ConfigScope):
        """ä¿å­˜æŒ‡å®šä½œç”¨åŸŸçš„é…ç½®"""
        if scope not in self.config_cache:
            return
            
        config_file = self.config_files[scope]
        try:
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(self.config_cache[scope], f, 
                         indent=2, ensure_ascii=False)
                logger.debug(f"ä¿å­˜é…ç½®æ–‡ä»¶: {config_file}")
        except IOError as e:
            logger.error(f"ä¿å­˜é…ç½®æ–‡ä»¶å¤±è´¥ {config_file}: {e}")
            
    def _apply_default_configs(self):
        """åº”ç”¨é»˜è®¤é…ç½®"""
        for key, config_item in self.config_schema.items():
            scope = config_item.scope
            if scope not in self.config_cache:
                self.config_cache[scope] = {}
                
            # å¦‚æœé…ç½®ä¸å­˜åœ¨ï¼Œåˆ™ä½¿ç”¨é»˜è®¤å€¼
            if key not in self.config_cache[scope]:
                self.config_cache[scope][key] = config_item.default_value
                logger.debug(f"åº”ç”¨é»˜è®¤é…ç½®: {key} = {config_item.default_value}")
                
    def _notify_config_change(self, key: str, old_value: Any, new_value: Any):
        """é€šçŸ¥é…ç½®å˜æ›´"""
        for listener in self.change_listeners:
            try:
                listener(key, old_value, new_value)
            except Exception as e:
                logger.error(f"é…ç½®å˜æ›´ç›‘å¬å™¨é”™è¯¯: {e}")
```

### é…ç½®åˆå§‹åŒ–æœåŠ¡
```python
class ConfigInitializationService:
    """é…ç½®åˆå§‹åŒ–æœåŠ¡"""
    
    def __init__(self, config_manager: ConfigurationManager):
        self.config_manager = config_manager
        self.system_detector = SystemDetector()
        
    def initialize_on_first_run(self) -> bool:
        """é¦–æ¬¡è¿è¡Œåˆå§‹åŒ–"""
        try:
            logger.info("æ£€æµ‹åˆ°é¦–æ¬¡è¿è¡Œï¼Œå¼€å§‹åˆå§‹åŒ–é…ç½®...")
            
            # 1. æ£€æµ‹ç³»ç»Ÿç¯å¢ƒ
            system_info = self.system_detector.detect_system_capabilities()
            
            # 2. æ™ºèƒ½é…ç½®æ¨è
            recommended_config = self.generate_recommended_config(system_info)
            
            # 3. åº”ç”¨æ¨èé…ç½®
            self.apply_recommended_config(recommended_config)
            
            # 4. åˆ›å»ºåˆå§‹ç›®å½•ç»“æ„
            self.create_initial_directories()
            
            # 5. è®¾ç½®åˆå§‹åŒ–æ ‡è®°
            self.config_manager.set("app.first_run_completed", True)
            
            logger.info("åˆå§‹åŒ–é…ç½®å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–é…ç½®å¤±è´¥: {e}")
            return False
            
    def generate_recommended_config(self, system_info: SystemInfo) -> Dict[str, Any]:
        """ç”Ÿæˆæ¨èé…ç½®"""
        recommended = {}
        
        # æ ¹æ®ç³»ç»Ÿå†…å­˜è°ƒæ•´AIæ¨¡å‹è®¾ç½®
        if system_info.total_memory < 4 * 1024 * 1024 * 1024:  # 4GB
            recommended["model.device"] = "cpu"
            recommended["diagnosis.enable_realtime"] = False
            logger.info("æ£€æµ‹åˆ°ä½å†…å­˜ç³»ç»Ÿï¼Œä¼˜åŒ–AIæ¨¡å‹é…ç½®")
        elif system_info.has_gpu:
            recommended["model.device"] = "cuda"
            logger.info("æ£€æµ‹åˆ°GPUï¼Œå¯ç”¨GPUåŠ é€Ÿ")
        else:
            recommended["model.device"] = "cpu"
            
        # æ ¹æ®å±å¹•åˆ†è¾¨ç‡è°ƒæ•´çª—å£å¤§å°
        if system_info.screen_width < 1366:
            recommended["gui.window_width"] = 1024
            recommended["gui.window_height"] = 768
        elif system_info.screen_width >= 1920:
            recommended["gui.window_width"] = 1400
            recommended["gui.window_height"] = 900
            
        # æ ¹æ®ç³»ç»Ÿç±»å‹è°ƒæ•´ç›‘æ§é—´éš”
        if system_info.is_server:
            recommended["diagnosis.scan_interval"] = 600  # æœåŠ¡å™¨æ¨¡å¼ï¼Œè¾ƒé•¿é—´éš”
        else:
            recommended["diagnosis.scan_interval"] = 300  # æ¡Œé¢æ¨¡å¼
            
        # æ ¹æ®ç½‘ç»œç¯å¢ƒè°ƒæ•´æ›´æ–°é…ç½®
        if system_info.network_speed < 10:  # 10 Mbps
            recommended["update.auto_download"] = False
            logger.info("æ£€æµ‹åˆ°ä½é€Ÿç½‘ç»œï¼Œç¦ç”¨è‡ªåŠ¨ä¸‹è½½")
            
        return recommended
        
    def apply_recommended_config(self, recommended_config: Dict[str, Any]):
        """åº”ç”¨æ¨èé…ç½®"""
        for key, value in recommended_config.items():
            if self.config_manager.set(key, value, persist=False):
                logger.info(f"åº”ç”¨æ¨èé…ç½®: {key} = {value}")
            else:
                logger.warning(f"åº”ç”¨æ¨èé…ç½®å¤±è´¥: {key} = {value}")
                
    def create_initial_directories(self):
        """åˆ›å»ºåˆå§‹ç›®å½•ç»“æ„"""
        base_dir = Path.home() / ".sysgraph"
        
        directories = [
            base_dir / "models",
            base_dir / "logs", 
            base_dir / "cache",
            base_dir / "backups",
            base_dir / "downloads",
            base_dir / "plugins"
        ]
        
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
            logger.debug(f"åˆ›å»ºç›®å½•: {directory}")

class SystemDetector:
    """ç³»ç»Ÿç¯å¢ƒæ£€æµ‹å™¨"""
    
    def detect_system_capabilities(self) -> 'SystemInfo':
        """æ£€æµ‹ç³»ç»Ÿèƒ½åŠ›"""
        import psutil
        import platform
        
        # åŸºæœ¬ç³»ç»Ÿä¿¡æ¯
        system_info = SystemInfo()
        system_info.platform = platform.system()
        system_info.cpu_count = psutil.cpu_count()
        system_info.total_memory = psutil.virtual_memory().total
        
        # æ£€æµ‹GPU
        system_info.has_gpu = self.detect_gpu()
        
        # æ£€æµ‹å±å¹•åˆ†è¾¨ç‡
        system_info.screen_width, system_info.screen_height = self.detect_screen_resolution()
        
        # æ£€æµ‹ç³»ç»Ÿç±»å‹
        system_info.is_server = self.detect_server_environment()
        
        # æ£€æµ‹ç½‘ç»œé€Ÿåº¦
        system_info.network_speed = self.detect_network_speed()
        
        return system_info
        
    def detect_gpu(self) -> bool:
        """æ£€æµ‹GPUæ”¯æŒ"""
        try:
            import torch
            return torch.cuda.is_available()
        except ImportError:
            return False
            
    def detect_screen_resolution(self) -> tuple:
        """æ£€æµ‹å±å¹•åˆ†è¾¨ç‡"""
        try:
            from PyQt6.QtWidgets import QApplication
            from PyQt6.QtGui import QGuiApplication
            
            app = QGuiApplication.instance()
            if app is None:
                app = QGuiApplication([])
                
            screen = app.primaryScreen()
            size = screen.size()
            return size.width(), size.height()
        except Exception:
            return 1920, 1080  # é»˜è®¤åˆ†è¾¨ç‡
            
    def detect_server_environment(self) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸ºæœåŠ¡å™¨ç¯å¢ƒ"""
        import os
        
        # æ£€æŸ¥ç¯å¢ƒå˜é‡
        server_indicators = [
            'SSH_CLIENT', 'SSH_TTY', 'DISPLAY' 
        ]
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ˜¾ç¤ºè®¾å¤‡
        has_display = bool(os.environ.get('DISPLAY')) or bool(os.environ.get('WAYLAND_DISPLAY'))
        
        # SSHè¿æ¥æˆ–æ— æ˜¾ç¤ºè®¾å¤‡å¯èƒ½æ˜¯æœåŠ¡å™¨
        is_ssh = any(var in os.environ for var in ['SSH_CLIENT', 'SSH_TTY'])
        
        return is_ssh or not has_display
        
    def detect_network_speed(self) -> float:
        """æ£€æµ‹ç½‘ç»œé€Ÿåº¦ (Mbps)"""
        # ç®€å•çš„ç½‘ç»œé€Ÿåº¦æ£€æµ‹
        try:
            import time
            import requests
            
            start_time = time.time()
            response = requests.get('https://httpbin.org/bytes/1048576', timeout=10)  # 1MB
            end_time = time.time()
            
            if response.status_code == 200:
                duration = end_time - start_time
                speed_mbps = (1 * 8) / duration  # 1MB = 8Mb
                return speed_mbps
        except Exception:
            pass
            
        return 100.0  # é»˜è®¤å€¼

@dataclass 
class SystemInfo:
    platform: str = ""
    cpu_count: int = 0
    total_memory: int = 0
    has_gpu: bool = False
    screen_width: int = 1920
    screen_height: int = 1080
    is_server: bool = False
    network_speed: float = 100.0
```
  theme: "dark"
  language: "zh-CN"
  window_size: [1200, 800]
  auto_refresh_interval: 5  # ç§’
```

### é…ç½®ç®¡ç†å™¨
```python
class ConfigManager:
    def __init__(self):
        self.config_path = "config.yaml"
        self.config = self.load_config()
        
    def load_config(self) -> Dict
    def save_config(self, config: Dict) -> None
    def get(self, key: str, default=None) -> Any
    def set(self, key: str, value: Any) -> None
```

## é”™è¯¯å¤„ç†ä¸æ—¥å¿—

### å¼‚å¸¸å¤„ç†ç­–ç•¥
```python
class DiagnosticError(Exception):
    pass

class ModelLoadError(DiagnosticError):
    pass

class DataCollectionError(DiagnosticError):
    pass

class NetworkError(DiagnosticError):
    pass
```

### æ—¥å¿—ç³»ç»Ÿ
```python
from loguru import logger

logger.add(
    "logs/diagnostic_{time}.log",
    rotation="1 day",
    retention="30 days",
    level="INFO"
)
```

**æ—¥å¿—çº§åˆ«**:
- `ERROR`: ç³»ç»Ÿé”™è¯¯å’Œå¼‚å¸¸
- `WARNING`: æ½œåœ¨é—®é¢˜å’Œè­¦å‘Š
- `INFO`: å¸¸è§„æ“ä½œä¿¡æ¯
- `DEBUG`: è¯¦ç»†è°ƒè¯•ä¿¡æ¯

## æ€§èƒ½ä¼˜åŒ–

### å†…å­˜ç®¡ç†
- æ¨¡å‹æ‡’åŠ è½½æœºåˆ¶
- æ•°æ®æ”¶é›†ç»“æœç¼“å­˜
- å®šæœŸå†…å­˜æ¸…ç†

### å¹¶å‘å¤„ç†
- å¼‚æ­¥æ•°æ®æ”¶é›†
- å¤šçº¿ç¨‹UIæ›´æ–°
- æ™ºèƒ½ä½“å¹¶è¡Œæ‰§è¡Œ

### å“åº”ä¼˜åŒ–
- å¢é‡æ•°æ®æ›´æ–°
- UIæ¸²æŸ“ä¼˜åŒ–
- åå°ä»»åŠ¡è°ƒåº¦

```python
class PerformanceManager:
    def __init__(self):
        self.memory_monitor = MemoryMonitor()
        self.task_scheduler = TaskScheduler()
        
    def optimize_memory_usage(self) -> None
    def schedule_background_tasks(self) -> None
    def monitor_performance_metrics(self) -> PerformanceMetrics
```